{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wizards Staff - Quickstart Tutorial\n",
    "\n",
    "<img src=\"../img/wizards_staff.png\" alt=\"Wizards Staff logo\" width=\"400\"/>\n",
    "\n",
    "This tutorial provides a comprehensive introduction to using the Wizards Staff package for calcium imaging analysis. By the end of this notebook, you'll understand how to:\n",
    "\n",
    "1. Set up and initialize Wizards Staff\n",
    "2. Process calcium imaging data\n",
    "3. Extract key metrics like rise time, FWHM, and firing rates\n",
    "4. Generate visualizations\n",
    "5. Work with and interpret the results\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Setup\n",
    "\n",
    "First, let's install the Wizards Staff package. You can either use pip or install directly from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you need to install Wizards Staff\n",
    "# !pip install git+https://github.com/ArcInstitute/Wizards-Staff.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Import the main Orb class from Wizards Staff\n",
    "from wizards_staff import Orb\n",
    "\n",
    "# Set up matplotlib for better visualizations\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Data Requirements\n",
    "\n",
    "Before we begin, it's important to understand what data Wizards Staff expects. The package is designed to work with the outputs from calcium imaging pipelines like [Lizard-Wizard](https://github.com/ArcInstitute/Lizard-Wizard) or [CaImAn](https://github.com/flatironinstitute/CaImAn).\n",
    "\n",
    "### Required Input Files\n",
    "\n",
    "For each sample, Wizards Staff looks for the following files in your results folder:\n",
    "\n",
    "- `{sample_name}_dff-dat.npy`: Delta F/F0 (ΔF/F₀) matrix\n",
    "- `{sample_name}_cnm-A.npy`: Spatial footprints from CaImAn\n",
    "- `{sample_name}_cnm-idx.npy`: Indices of accepted components\n",
    "- `{sample_name}_minprojection.tif`: Minimum projection image\n",
    "\n",
    "### Metadata Format\n",
    "\n",
    "You also need a metadata CSV file with at least the following columns:\n",
    "- `Sample`: Unique identifier for each sample, matching filenames\n",
    "- `Well`: Well identifier (or other grouping variable)\n",
    "- `Frate`: Frame rate of the recording in frames per second\n",
    "\n",
    "Let's take a look at a sample metadata file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample metadata structure\n",
    "metadata_example = pd.DataFrame({\n",
    "    'Sample': ['10xGCaMP-6wk-Baseline-Stream_Stream_F07_s1_FITC_full', \n",
    "               '10xGCaMP-6wk-Baseline-Stream_Stream_G03_s1_FITC_full'],\n",
    "    'Well': ['F07', 'G03'],\n",
    "    'Frate': [30, 30]\n",
    "})\n",
    "\n",
    "print(\"Example metadata format:\")\n",
    "metadata_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initializing the Orb\n",
    "\n",
    "The main entry point for Wizards Staff is the `Orb` class. It organizes your data and provides methods for analysis.\n",
    "\n",
    "Let's initialize an Orb with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to your data\n",
    "# Update these paths to match your own data locations\n",
    "results_folder = \"path/to/your/calcium_imaging_results\"\n",
    "metadata_path = \"path/to/your/metadata.csv\"\n",
    "\n",
    "# Initialize the Orb\n",
    "orb = Orb(\n",
    "    results_folder=results_folder,\n",
    "    metadata_file_path=metadata_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what the Orb found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what samples were found\n",
    "print(f\"Found {len(orb.samples)} samples:\")\n",
    "print(orb.samples)\n",
    "\n",
    "# Check available data items\n",
    "print(\"\\nAvailable data items:\")\n",
    "if orb.input_files is not None:\n",
    "    print(set(orb.input_files['DataItem']))\n",
    "else:\n",
    "    print(\"No input files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running a Complete Analysis\n",
    "\n",
    "The simplest way to use Wizards Staff is to run all analyses at once using the `run_all` method. This will calculate metrics like rise time, FWHM, and firing rates for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all analyses at once\n",
    "orb.run_all(\n",
    "    group_name=\"Well\",         # Group samples by this metadata column\n",
    "    frate=30,                  # Frame rate in frames per second\n",
    "    zscore_threshold=3,        # Threshold for spike detection\n",
    "    percentage_threshold=0.2,  # Threshold for FWHM calculation\n",
    "    p_th=75,                   # Percentile threshold for spatial filtering\n",
    "    min_clusters=2,            # Minimum number of clusters for K-means\n",
    "    max_clusters=10,           # Maximum number of clusters for K-means\n",
    "    size_threshold=20000,      # Threshold for filtering out noise\n",
    "    show_plots=True,           # Show plots during analysis\n",
    "    save_files=False           # Don't save files in this example\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Accessing and Visualizing Results\n",
    "\n",
    "After running the analysis, we can access the results as pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access rise time data\n",
    "rise_time_df = orb.rise_time_data\n",
    "if rise_time_df is not None:\n",
    "    print(\"Rise Time Data:\")\n",
    "    display(rise_time_df.head())\n",
    "else:\n",
    "    print(\"No rise time data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access FWHM data\n",
    "fwhm_df = orb.fwhm_data\n",
    "if fwhm_df is not None:\n",
    "    print(\"FWHM Data:\")\n",
    "    display(fwhm_df.head())\n",
    "else:\n",
    "    print(\"No FWHM data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access firing rate data\n",
    "frpm_df = orb.frpm_data\n",
    "if frpm_df is not None:\n",
    "    print(\"Firing Rate Data:\")\n",
    "    display(frpm_df.head())\n",
    "else:\n",
    "    print(\"No firing rate data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some basic visualizations of our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize firing rates by well\n",
    "if frpm_df is not None:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Calculate mean firing rate per well\n",
    "    well_means = frpm_df.groupby('Well')['Firing Rate Per Min.'].mean().sort_values()\n",
    "    \n",
    "    # Create a bar plot\n",
    "    well_means.plot(kind='bar', color='steelblue')\n",
    "    plt.title('Average Firing Rate by Well', fontsize=14)\n",
    "    plt.ylabel('Firing Rate (events/min)', fontsize=12)\n",
    "    plt.xlabel('Well', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Step-by-Step Analysis\n",
    "\n",
    "For more control, we can process samples (shards) individually. This allows us to customize the analysis for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sample\n",
    "shard = next(orb.shatter())\n",
    "print(f\"Processing sample: {shard.sample_name}\")\n",
    "\n",
    "# Check available files for this sample\n",
    "print(\"\\nAvailable files:\")\n",
    "for item_name, (file_path, _) in shard.files.items():\n",
    "    print(f\"  {item_name}: {os.path.basename(file_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply spatial filtering\n",
    "filtered_idx = shard.spatial_filtering(\n",
    "    p_th=75,                # Percentile threshold\n",
    "    size_threshold=20000,   # Size threshold\n",
    "    plot=True,              # Show the plot\n",
    "    silence=False           # Show information\n",
    ")\n",
    "\n",
    "print(f\"\\nFiltered neurons: {len(filtered_idx)} out of {len(shard.get_input('cnm_idx'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to calcium signals and spike events\n",
    "calcium_signals, spike_events = shard.convert_f_to_cs(p=2)\n",
    "\n",
    "# Z-score the spike events for better detection\n",
    "zscored_spike_events = zscore(np.copy(spike_events), axis=1)\n",
    "\n",
    "print(f\"Calcium signals shape: {calcium_signals.shape}\")\n",
    "print(f\"Spike events shape: {spike_events.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rise time for filtered neurons\n",
    "rise_times, rise_positions = shard.calc_rise_tm(\n",
    "    calcium_signals[filtered_idx],\n",
    "    zscored_spike_events[filtered_idx],\n",
    "    zscore_threshold=3\n",
    ")\n",
    "\n",
    "# Count events per neuron\n",
    "events_per_neuron = {idx: len(times) for idx, times in rise_times.items()}\n",
    "neurons_with_events = sum(1 for count in events_per_neuron.values() if count > 0)\n",
    "\n",
    "print(f\"Detected rise events in {neurons_with_events} out of {len(filtered_idx)} neurons\")\n",
    "print(f\"Average events per neuron: {np.mean(list(events_per_neuron.values())):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FWHM for filtered neurons\n",
    "fwhm_pos_back, fwhm_pos_fwd, fwhm_values, spike_counts = shard.calc_fwhm_spikes(\n",
    "    calcium_signals[filtered_idx],\n",
    "    zscored_spike_events[filtered_idx],\n",
    "    zscore_threshold=3,\n",
    "    percentage_threshold=0.2\n",
    ")\n",
    "\n",
    "# Count FWHM events per neuron\n",
    "fwhm_per_neuron = {idx: len(values) for idx, values in fwhm_values.items()}\n",
    "neurons_with_fwhm = sum(1 for count in fwhm_per_neuron.values() if count > 0)\n",
    "\n",
    "print(f\"Calculated FWHM for {neurons_with_fwhm} out of {len(filtered_idx)} neurons\")\n",
    "\n",
    "# Calculate average FWHM value\n",
    "all_fwhm_values = [val for neuron_values in fwhm_values.values() for val in neuron_values]\n",
    "if all_fwhm_values:\n",
    "    print(f\"Average FWHM: {np.mean(all_fwhm_values):.2f} frames\")\n",
    "else:\n",
    "    print(\"No FWHM values found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate firing rate per minute (FRPM)\n",
    "frpm_avg, spike_dict = shard.calc_frpm(\n",
    "    zscored_spike_events,\n",
    "    filtered_idx,\n",
    "    frate=30,  # frames per second\n",
    "    zscore_threshold=3\n",
    ")\n",
    "\n",
    "print(f\"Average firing rate: {frpm_avg:.2f} events/minute\")\n",
    "print(f\"Firing rates range: {min(spike_dict.values()):.2f} to {max(spike_dict.values()):.2f} events/minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Neural Activity\n",
    "\n",
    "Let's create some visualizations of neural activity using Wizards Staff's plotting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting functions\n",
    "from wizards_staff.plotting import plot_spatial_activity_map, plot_dff_activity, plot_cluster_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial activity map\n",
    "plot_spatial_activity_map(\n",
    "    im_min=shard.get_input('minprojection'),\n",
    "    cnm_A=shard.get_input('cnm_A'),\n",
    "    cnm_idx=filtered_idx,\n",
    "    sample_name=shard.sample_name,\n",
    "    clustering=False,  # Don't color by cluster in this example\n",
    "    show_plots=True,\n",
    "    save_files=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spatial activity map with clustering\n",
    "plot_spatial_activity_map(\n",
    "    im_min=shard.get_input('minprojection'),\n",
    "    cnm_A=shard.get_input('cnm_A'),\n",
    "    cnm_idx=filtered_idx,\n",
    "    sample_name=shard.sample_name,\n",
    "    clustering=True,  # Color by cluster\n",
    "    dff_dat=shard.get_input('dff_dat'),  # Required for clustering\n",
    "    show_plots=True,\n",
    "    save_files=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot activity traces\n",
    "plot_dff_activity(\n",
    "    dff_dat=shard.get_input('dff_dat'),\n",
    "    cnm_idx=filtered_idx,\n",
    "    frate=30,  # frames per second\n",
    "    sample_name=shard.sample_name,\n",
    "    max_z=0.6,  # maximum ΔF/F₀ intensity for scaling\n",
    "    begin_tp=0,  # starting time point\n",
    "    end_tp=1000,  # ending time point (first 33 seconds at 30 fps)\n",
    "    show_plots=True,\n",
    "    save_files=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cluster activity\n",
    "plot_cluster_activity(\n",
    "    dff_dat=shard.get_input('dff_dat'),\n",
    "    filtered_idx=filtered_idx,\n",
    "    sample_name=shard.sample_name,\n",
    "    min_clusters=2,\n",
    "    max_clusters=10,\n",
    "    random_seed=1111111,\n",
    "    norm=True,  # Normalize activity\n",
    "    show_plots=True,\n",
    "    save_files=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pairwise Correlation Analysis\n",
    "\n",
    "Pairwise correlation analysis helps identify functional connectivity between neurons. Let's run this analysis on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pairwise correlation analysis\n",
    "orb.run_pwc(\n",
    "    group_name=\"Well\",  # Group samples by this column\n",
    "    poly=True,          # Use polynomial fitting\n",
    "    p_th=75,            # Percentile threshold\n",
    "    size_threshold=20000,  # Size threshold\n",
    "    show_plots=True,    # Show plots\n",
    "    save_files=False    # Don't save files\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the pairwise correlation results\n",
    "pwc_df = orb.df_mn_pwc\n",
    "intra_df = orb.df_mn_pwc_intra  # Within-group correlations\n",
    "inter_df = orb.df_mn_pwc_inter  # Between-group correlations\n",
    "\n",
    "# Display the results\n",
    "if pwc_df is not None:\n",
    "    print(\"Overall Pairwise Correlations:\")\n",
    "    display(pwc_df)\n",
    "    \n",
    "    print(\"\\nIntra-group Correlations:\")\n",
    "    display(intra_df)\n",
    "    \n",
    "    print(\"\\nInter-group Correlations:\")\n",
    "    display(inter_df)\n",
    "else:\n",
    "    print(\"No pairwise correlation results available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Saving Results\n",
    "\n",
    "Finally, if not saved during the initial `run_all` function we can save our results to disk for further analysis or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"wizards_staff_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save all results\n",
    "orb.save_results(\n",
    "    outdir=output_dir,\n",
    "    result_names=[\n",
    "        \"rise_time_data\", \n",
    "        \"fwhm_data\", \n",
    "        \"frpm_data\", \n",
    "        \"mask_metrics_data\", \n",
    "        \"silhouette_scores_data\",\n",
    "        \"df_mn_pwc\", \n",
    "        \"df_mn_pwc_intra\", \n",
    "        \"df_mn_pwc_inter\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Results saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this tutorial, we've covered the basics of using Wizards Staff for calcium imaging analysis. We've learned how to:\n",
    "\n",
    "1. Set up and initialize the Orb with your data\n",
    "2. Run a complete analysis using `run_all`\n",
    "3. Process samples step-by-step for more control\n",
    "4. Calculate important metrics: rise time, FWHM, and firing rates\n",
    "5. Create visualizations of neural activity\n",
    "6. Perform pairwise correlation analysis\n",
    "7. Save and export results\n",
    "\n",
    "This is just the beginning of what you can do with Wizards Staff. For more advanced usage, check out the [API documentation](../docs/api.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
