{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wizards Staff Tutorial for Calcium Imaging Analysis\n",
        "\n",
        "<img src=\"../img/wizards_staff.png\" alt=\"Wizards Staff logo\" width=\"400\"/>\n",
        "\n",
        "---\n",
        "\n",
        "## Welcome Young Wizard\n",
        "\n",
        "This tutorial will guide you through analyzing your calcium imaging data using **Wizards Staff**. By the end, you'll be able to:\n",
        "\n",
        "- Load your processed calcium imaging data\n",
        "- Extract meaningful metrics about neuronal activity\n",
        "- Identify which neurons fire together (network analysis)\n",
        "- Visualize your results\n",
        "- Export data for statistical analysis\n",
        "\n",
        "---\n",
        "\n",
        "## What is Wizards Staff?\n",
        "\n",
        "**Wizards Staff** is a Python toolkit that takes the *processed* output from calcium imaging pipelines (like [Lizard-Wizard](https://github.com/ArcInstitute/Lizard-Wizard)) and extracts biologically meaningful metrics.\n",
        "\n",
        "### Biological Questions Wizards Staff Helps Answer:\n",
        "\n",
        "| Question | Wizards Staff Output |\n",
        "|----------|---------------------|\n",
        "| How active are my neurons? | **Firing rate** (spikes per minute) |\n",
        "| How quickly do neurons respond? | **Rise time** (time to peak) |\n",
        "| How long do calcium events last? | **FWHM** (event duration) |\n",
        "| Which neurons fire together? | **Pairwise correlations** |\n",
        "| Are there functional groups? | **K-means clustering** |\n",
        "| How do conditions compare? | **Group comparisons** |\n",
        "\n",
        "---\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before starting, you need:\n",
        "\n",
        "1. **Completed Lizard-Wizard run** â€” Your calcium imaging videos must already be processed\n",
        "2. **Output folder** â€” Know where your Lizard-Wizard results are saved\n",
        "3. **Metadata file** â€” A simple CSV file describing your samples (we'll show you how to make one)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ğŸ“š Notebook Structure\n",
        "\n",
        "This tutorial is organized into **four parts**. Depending on your experimental design, you may not need all of them:\n",
        "\n",
        "| Part | Sections | Who Should Read |\n",
        "|------|----------|-----------------|\n",
        "| **Part 1: Shared Setup** | 1-4 | Everyone |\n",
        "| **Part 2: Unpaired Group Comparisons** | 5-10 | Different samples per condition (Control vs Treated) |\n",
        "| **Part 3: Paired Drug Response** | 11-16 | Same samples before/after treatment |\n",
        "| **Part 4: Advanced & Reference** | 17-19 | Optional - power users and troubleshooting |\n",
        "\n",
        "**Quick Start:** Complete Part 1, then follow the decision guide in Section 4 to choose Part 2 or Part 3.\n",
        "\n",
        "---\n",
        "\n",
        "# Part 1: Shared Setup\n",
        "\n",
        "*Complete this section regardless of your experimental design.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 1: Understanding Your Input Files\n",
        "\n",
        "**Learning objective**: Know what files Wizards Staff needs and where to find them.\n",
        "\n",
        "---\n",
        "\n",
        "## Files from Lizard-Wizard\n",
        "\n",
        "When Lizard-Wizard finishes processing your videos, it creates several files for each sample. Here's what each file contains:\n",
        "\n",
        "| File Pattern | What It Contains | Plain English |\n",
        "|--------------|-----------------|---------------|\n",
        "| `*_dff-dat.npy` | Î”F/Fâ‚€ traces | The normalized calcium activity for each neuron over time |\n",
        "| `*_cnm-A.npy` | Spatial footprints | Where each neuron is located in the image |\n",
        "| `*_cnm-idx.npy` | Accepted components | Which detected \"cells\" passed quality control |\n",
        "| `*_minprojection.tif` | Reference image | A static image showing your field of view |\n",
        "| `*_masks.tif` | ROI masks | Outlines of each neuron (optional, for shape analysis) |\n",
        "| `*_f-dat.npy` | Raw fluorescence | The original brightness values before normalization |\n",
        "\n",
        "ğŸ’¡ **Tip**: The `*` represents your sample name. For example, if your sample is called `Experiment1_WellA01`, the files would be `Experiment1_WellA01_dff-dat.npy`, etc.\n",
        "\n",
        "### Finding Your Results Folder\n",
        "\n",
        "Your results folder is the `--output_dir` you specified when running Lizard-Wizard. It typically looks something like:\n",
        "\n",
        "```\n",
        "/path/to/lizard-wizard-output/\n",
        "â”œâ”€â”€ Sample1_dff-dat.npy\n",
        "â”œâ”€â”€ Sample1_cnm-A.npy\n",
        "â”œâ”€â”€ Sample1_cnm-idx.npy\n",
        "â”œâ”€â”€ Sample1_minprojection.tif\n",
        "â”œâ”€â”€ Sample2_dff-dat.npy\n",
        "â”œâ”€â”€ Sample2_cnm-A.npy\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: View sample metadata structure\n",
        "import pandas as pd\n",
        "\n",
        "metadata_example = pd.DataFrame({\n",
        "    'Sample': ['Exp1_DMSO_A01_s1', 'Exp1_DMSO_A02_s1', 'Exp1_Drug_B01_s1', 'Exp1_Drug_B02_s1'],\n",
        "    'Well': ['Control', 'Control', 'Treated', 'Treated'],\n",
        "    'Frate': [30, 30, 30, 30]\n",
        "})\n",
        "\n",
        "print(\"Example metadata format:\")\n",
        "display(metadata_example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Your Metadata File\n",
        "\n",
        "The metadata file tells Wizards Staff about your experimental design. It's a simple CSV (spreadsheet) with **three required columns**:\n",
        "\n",
        "| Column | Description | Example |\n",
        "|--------|-------------|--------|\n",
        "| `Sample` | Unique name matching your filenames | `Experiment1_WellA01` |\n",
        "| `Well` | Group/condition identifier | `Control`, `Treated`, `A01`, etc. |\n",
        "| `Frate` | Recording frame rate (frames per second) | `30` |\n",
        "\n",
        "### Example Metadata File\n",
        "\n",
        "Here's what your `metadata.csv` might look like:\n",
        "\n",
        "```csv\n",
        "Sample,Well,Frate\n",
        "Exp1_DMSO_A01_s1,Control,30\n",
        "Exp1_DMSO_A02_s1,Control,30\n",
        "Exp1_Drug_B01_s1,Treated,30\n",
        "Exp1_Drug_B02_s1,Treated,30\n",
        "```\n",
        "\n",
        "âš ï¸ **Important**: The `Sample` column must **exactly match** the prefix of your filenames (everything before `_dff-dat.npy`).\n",
        "\n",
        "**Tip**: You can create this file in Excel and save it as CSV, or use any text editor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  SECTION 2: SETUP AND INSTALLATION                                          â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# INSTALLATION (only need to run this once)\n",
        "# -----------------------------------------\n",
        "# Remove the '#' from the line below and run this cell if you haven't installed Wizards Staff yet.\n",
        "# After installation, you can add the '#' back to skip this step in future sessions.\n",
        "\n",
        "# !pip install git+https://github.com/ArcInstitute/Wizards-Staff.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: Setup and Installation\n",
        "\n",
        "**Learning objective**: Install Wizards Staff and import it into Python.\n",
        "\n",
        "---\n",
        "\n",
        "Run the cell above to install (if needed), then run the cell below to import the main tools from our package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORT THE MAIN TOOLS\n",
        "# ---------------------\n",
        "# These are the Python packages we'll use throughout this tutorial.\n",
        "\n",
        "# The main Wizards Staff class - this is the \"container\" for all your data\n",
        "from wizards_staff import Orb\n",
        "\n",
        "# Standard tools for viewing data (optional but helpful)\n",
        "import matplotlib.pyplot as plt  # For viewing plots\n",
        "\n",
        "# Make plots appear directly in the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"All packages loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is an \"Orb\"?\n",
        "\n",
        "Think of the **Orb** as your **crystal ball** that:\n",
        "- Organizes all your samples in one place\n",
        "- Keeps track of which files belong to which sample\n",
        "- Provides all the analysis methods you need\n",
        "- Stores your results for easy access\n",
        "\n",
        "You'll create one Orb, and it will handle everything from there.\n",
        "\n",
        "---\n",
        "\n",
        "# Section 3: Loading Your Data\n",
        "\n",
        "**Learning objective**: Create an Orb and load your calcium imaging data.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 3.1: Set Your File Paths\n",
        "\n",
        "You need to tell Wizards Staff where to find your data. **Edit the paths below** to match your own files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  âš ï¸ EDIT THESE PATHS TO MATCH YOUR DATA  âš ï¸                                â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Path to your Lizard-Wizard output folder\n",
        "# This is the folder containing all the *_dff-dat.npy, *_cnm-A.npy, etc. files\n",
        "RESULTS_FOLDER = \"/path/to/your/lizard-wizard-output/\"\n",
        "RESULTS_FOLDER = \"/large_storage/cmtc/public/CMTC-Sph10162025-plateB-week5\"\n",
        "# Path to your metadata CSV file\n",
        "# This is the spreadsheet you created with Sample, Well, and Frate columns\n",
        "METADATA_FILE = \"/path/to/your/metadata.csv\"\n",
        "METADATA_FILE = \"/large_storage/cmtc/public/CMTC-Sph10162025-plateB-week5/metadata.csv\"\n",
        "# Where to save your analysis results\n",
        "# A new folder will be created if it doesn't exist\n",
        "OUTPUT_FOLDER = \"./my_analysis_results/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3.2: Create the Orb\n",
        "\n",
        "Now we'll create an Orb with your data. This step:\n",
        "1. Reads your metadata file\n",
        "2. Scans for all matching data files\n",
        "3. Validates that files exist for each sample\n",
        "4. Reports any missing files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE THE ORB\n",
        "# --------------\n",
        "# This creates your \"crystal ball\" and loads information about all your samples.\n",
        "\n",
        "orb = Orb(\n",
        "    results_folder=RESULTS_FOLDER,      # Where your data files are\n",
        "    metadata_file_path=METADATA_FILE    # Your experimental design info\n",
        ")\n",
        "\n",
        "# Show what was found\n",
        "print(f\"\\n Found {len(orb.samples)} samples in your metadata\")\n",
        "print(f\"\\n Sample names:\")\n",
        "for sample in sorted(orb.samples):\n",
        "    print(f\"   â€¢ {sample}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What to Look For\n",
        "\n",
        " **Success**: You should see a list of your sample names with no errors.\n",
        "\n",
        "âš ï¸ **Warnings about missing files**: Some samples may be missing certain files. Common causes:\n",
        "- Typos in the `Sample` column of your metadata\n",
        "- Files in a different folder\n",
        "- Lizard-Wizard didn't finish processing some samples\n",
        "\n",
        "**Tip**: If you see warnings, double-check that your `Sample` names exactly match the file prefixes.\n",
        "\n",
        "## Step 3.3: Check What Files Were Found (Optional)\n",
        "\n",
        "You can verify which data types are available for your samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHECK AVAILABLE DATA TYPES\n",
        "# --------------------------\n",
        "# This shows which types of files were found across all samples.\n",
        "\n",
        "if orb.input_files is not None:\n",
        "    available_data = set(orb.input_files['DataItem'])\n",
        "    print(\"Available data types:\")\n",
        "    for data_type in sorted(available_data):\n",
        "        print(f\"   âœ“ {data_type}\")\n",
        "else:\n",
        "    print(\"âŒ No input files found. Please check your RESULTS_FOLDER path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 4: Choose Your Analysis Workflow\n",
        "\n",
        "Determine which analysis track matches your experimental design.\n",
        "\n",
        "---\n",
        "\n",
        "Now that your data is loaded, the next step depends on your **experimental design**. Wizards Staff supports two fundamentally different workflows:\n",
        "\n",
        "## Which Workflow Matches Your Experiment?\n",
        "\n",
        "| If your experiment has... | Design Type | Statistical Approach | Go To |\n",
        "|---------------------------|-------------|---------------------|-------|\n",
        "| **Different samples** in Control vs Treatment groups | Unpaired | Independent samples tests | **Part 2 (Section 5)** |\n",
        "| **Same samples** imaged before AND after treatment | Paired | Paired tests, fold-change | **Part 3 (Section 11)** |\n",
        "\n",
        "---\n",
        "\n",
        "## Examples of Each Design\n",
        "\n",
        "### ğŸ”µ Unpaired Design (Part 2)\n",
        "\n",
        "Use Part 2 if you have **different samples** in each experimental condition:\n",
        "\n",
        "- Comparing firing rates between **wild-type and knockout** organoids\n",
        "- Testing **multiple drug concentrations** on separate wells  \n",
        "- **Control group on Plate 1**, Treated group on Plate 2\n",
        "- Comparing **different cell lines** or **genotypes**\n",
        "\n",
        "**Statistical approach**: Independent t-test, Mann-Whitney U, ANOVA\n",
        "\n",
        "â¡ï¸ **Continue to Section 5** (you're already in the right place!)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸŸ¢ Paired Design (Part 3)\n",
        "\n",
        "Use Part 3 if you image the **same samples at two timepoints**:\n",
        "\n",
        "- Baseline recording â†’ **apply drug** â†’ record same organoid again\n",
        "- Pre-treatment â†’ **drug wash-in** â†’ post-treatment  \n",
        "- Same wells imaged at **Day 0 and Day 7**\n",
        "- **Washout experiments**: baseline â†’ drug â†’ wash â†’ recovery\n",
        "\n",
        "**Statistical approach**: Paired t-test, fold-change normalization\n",
        "\n",
        "â¡ï¸ **Skip Ahead to** Part 3: Paired Drug Response Analysis)\n",
        "\n",
        "---\n",
        "\n",
        "## Still Unsure?\n",
        "\n",
        "Ask yourself: *\"Do my Control and Treated data come from the same physical samples?\"*\n",
        "\n",
        "- **YES** â†’ Part 3 (Paired)\n",
        "- **NO** â†’ Part 2 (Unpaired)\n",
        "\n",
        "*Note: You can always come back and try the other workflow later. The Orb you've created works with both.*\n",
        "\n",
        "---\n",
        "\n",
        "# Part 2: Unpaired Group Comparisons\n",
        "\n",
        "*For experiments with different samples in each condition.*\n",
        "\n",
        "This part covers:\n",
        "- Running the standard analysis pipeline\n",
        "- Understanding neural activity metrics (firing rate, event kinetics, clustering)\n",
        "- Correlation and network synchrony analysis\n",
        "- Statistical comparisons between groups\n",
        "- Creating publication-ready figures\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 5: Running the Analysis Pipeline\n",
        "\n",
        "**Learning objective**: Run the complete analysis pipeline with one command.\n",
        "\n",
        "---\n",
        "\n",
        "## The `run_all` Method\n",
        "\n",
        "The fastest way to analyze all your samples is using `run_all()`. This single command:\n",
        "\n",
        "1.  **Filters** neurons to remove noise and artifacts\n",
        "2.  **Detects** calcium transients (spikes) in each neuron\n",
        "3.  **Calculates** rise times, peak durations, and firing rates\n",
        "4.  **Clusters** neurons into functional groups\n",
        "5.  **Computes** correlations between neurons\n",
        "6.  **Generates** visualizations\n",
        "\n",
        "---\n",
        "\n",
        "## Understanding the Parameters\n",
        "\n",
        "Before running, let's understand what each setting does:\n",
        "\n",
        "### Essential Parameters (You Should Adjust These)\n",
        "\n",
        "| Parameter | What It Does | How to Set It |\n",
        "|-----------|--------------|---------------|\n",
        "| `group_name` | Column for **comparing conditions** | Use `\"Well\"` or another column from your metadata |\n",
        "| `show_plots` | **Display** plots in the notebook | `True` to preview, `False` for faster processing |\n",
        "| `save_files` | **Save** results to disk | `True` when you're ready to export |\n",
        "| `output_dir` | **Where** to save files | A folder path (will be created if needed) |\n",
        "\n",
        "### Advanced Parameters (Usually Leave as Default)\n",
        "\n",
        "| Parameter | What It Does | Default | When to Change |\n",
        "|-----------|--------------|---------|----------------|\n",
        "| `zscore_threshold` | How strong a signal must be to count as a \"spike\" | `3` | Lower (e.g., 2) if missing events; higher (e.g., 4) if too much noise |\n",
        "| `p_th` | Brightness percentile for filtering dim neurons | `75` | Lower if losing too many neurons; higher if including artifacts |\n",
        "| `size_threshold` | Maximum neuron size (pixels) | `20000` | Increase if neurons appear large; decrease to filter artifacts |\n",
        "| `min_clusters` / `max_clusters` | Range for finding neuron groups | `2` / `10` | Adjust based on expected functional populations |\n",
        "\n",
        "---\n",
        "\n",
        "### What is a Z-score?\n",
        "\n",
        "A **z-score** tells you how unusual a value is compared to the average:\n",
        "- **Z = 0**: Average activity\n",
        "- **Z = 1**: One standard deviation above average\n",
        "- **Z = 3**: Three standard deviations above average (very unusual = likely a real spike)\n",
        "\n",
        "With `zscore_threshold=3`, we only count events that are 3 standard deviations above the baseline â€” this helps distinguish real calcium transients from random noise.\n",
        "\n",
        "## Step 4.1: Run the Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  RUN THE COMPLETE ANALYSIS PIPELINE                                        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "orb.run_all(\n",
        "    # â”€â”€ Essential settings (adjust these) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    group_name=\"Well\",         # Group by: Which metadata column defines your conditions?\n",
        "    \n",
        "    # â”€â”€ Output settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    show_plots=False,           # Show plots: True = see plots now; False = faster\n",
        "    save_files=False,           # Save results: True = export to files; False = just compute\n",
        "    output_dir=OUTPUT_FOLDER,  # Where to save (uses OUTPUT_FOLDER from above)\n",
        "    \n",
        "    # â”€â”€ Spike detection settings (usually leave as default) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    zscore_threshold=3,        # Spike sensitivity: Lower = more sensitive (2-5 typical)\n",
        "    percentage_threshold=0.2,  # FWHM threshold: For measuring event duration\n",
        "    \n",
        "    # â”€â”€ Neuron filtering settings (usually leave as default) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    p_th=75,                   # Brightness filter: Remove dim/noisy components (0-100)\n",
        "    size_threshold=20000,      # Size filter: Remove artifacts larger than this (pixels)\n",
        "    \n",
        "    # â”€â”€ Clustering settings (usually leave as default) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    min_clusters=2,            # Minimum groups: Fewest functional clusters to try\n",
        "    max_clusters=10,           # Maximum groups: Most functional clusters to try\n",
        "    \n",
        "    # â”€â”€ Performance settings (adjust if kernel crashes) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    threads=2,                 # Sequential processing: Use 1 to avoid memory issues\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What You Should See\n",
        "\n",
        "During analysis, you'll see:\n",
        "1. **Progress messages** as each sample is processed\n",
        "2. **Activity maps** showing where neurons are located\n",
        "3. **Cluster plots** showing functional neuron groups\n",
        "4. **Trace plots** showing calcium activity over time\n",
        "5. **Correlation plots** (if `group_name` was provided)\n",
        "\n",
        "âš ï¸ **If you see warnings**: Some samples may be skipped due to missing files. This is normal if some recordings failed to be processed by Lizard Wizard.\n",
        "\n",
        "**Tip**: For large datasets, set `show_plots=False` to speed up processing and reduce memory load\n",
        "\n",
        "---\n",
        "\n",
        "# Section 6: Understanding Your Metrics\n",
        "\n",
        "**Learning objective**: Access and interpret the biological metrics from your analysis.\n",
        "\n",
        "---\n",
        "\n",
        "After running `run_all()`, your results are stored in the Orb as **DataFrames** (spreadsheet-like tables). Let's explore each one:\n",
        "\n",
        "## 6.1: Firing Rate Data\n",
        "\n",
        "### What It Measures\n",
        "**Firing rate** = How many calcium transients (\"spikes\") each neuron produces per minute.\n",
        "\n",
        "### Biological Interpretation\n",
        "-  **Higher firing rate** â†’ More active neurons\n",
        "-  **Lower firing rate** â†’ Less active or silent neurons\n",
        "-  Useful for comparing overall activity levels between conditions (e.g., drug vs. control)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW FIRING RATE DATA\n",
        "# ---------------------\n",
        "# This table shows how many spikes per minute each neuron produces.\n",
        "\n",
        "if orb.frpm_data is not None:\n",
        "    print(\"Firing Rate Data (spikes per minute)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Total neurons analyzed: {len(orb.frpm_data)}\")\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.frpm_data.head(10))\n",
        "    \n",
        "    # Quick summary statistics\n",
        "    print(f\"\\n Summary Statistics:\")\n",
        "    print(f\"   Mean firing rate: {orb.frpm_data['Firing Rate Per Min'].mean():.2f} spikes/min\")\n",
        "    print(f\"   Median firing rate: {orb.frpm_data['Firing Rate Per Min'].median():.2f} spikes/min\")\n",
        "    print(f\"   Range: {orb.frpm_data['Firing Rate Per Min'].min():.2f} - {orb.frpm_data['Firing Rate Per Min'].max():.2f} spikes/min\")\n",
        "else:\n",
        "    print(\"âŒ No firing rate data available. Did run_all() complete successfully?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2: Rise Time Data\n",
        "\n",
        "### What It Measures\n",
        "**Rise time** = How long it takes for a calcium signal to go from baseline to peak (in frames).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW RISE TIME DATA\n",
        "# -------------------\n",
        "# This table shows how quickly each neuron's calcium signals rise to peak.\n",
        "\n",
        "if orb.rise_time_data is not None:\n",
        "    print(\"Rise Time Data (frames to peak)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.rise_time_data.head(10))\n",
        "    \n",
        "    # Note about interpretation\n",
        "    print(\"\\n To convert to seconds: divide by your frame rate\")\n",
        "    print(f\"   Example: 10 frames at 30 fps = {10/30:.2f} seconds\")\n",
        "else:\n",
        "    print(\"âŒ No rise time data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.3: FWHM Data (Event Duration)\n",
        "\n",
        "### What It Measures\n",
        "**FWHM** (Full Width at Half Maximum) = How long a calcium event lasts, measured as the width of the peak at half its maximum height.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW FWHM DATA\n",
        "# --------------\n",
        "# This table shows the duration of calcium events for each neuron.\n",
        "\n",
        "if orb.fwhm_data is not None:\n",
        "    print(\"FWHM Data (event duration in frames)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.fwhm_data.head(10))\n",
        "else:\n",
        "    print(\"âŒ No FWHM data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.4: Clustering Data (Functional Groups)\n",
        "\n",
        "### What It Measures\n",
        "**Silhouette scores** = How well neurons separate into distinct functional groups based on their activity patterns.\n",
        "\n",
        "### Biological Interpretation\n",
        "- **Higher silhouette score** (closer to 1) â†’ Neurons form clear, distinct groups\n",
        "- **Lower silhouette score** (closer to 0) â†’ Groups overlap; neurons have similar activity patterns\n",
        "- Identifies co-active neuronal ensembles that may represent functional circuits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.5: Fall Time Data (Signal Decay)\n",
        "\n",
        "### What It Measures\n",
        "**Fall time** = How long it takes for a calcium signal to return from peak to baseline (in frames).\n",
        "\n",
        "### Biological Interpretation\n",
        "- **Longer fall time** â†’ Slower calcium clearance/buffering\n",
        "- **Shorter fall time** â†’ Faster signal termination\n",
        "- Together with rise time, provides a complete picture of calcium event kinetics\n",
        "- Can indicate differences in calcium handling machinery between neurons or conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW FALL TIME DATA\n",
        "# --------------------\n",
        "# This table shows how long each neuron's calcium signals take to decay from peak.\n",
        "\n",
        "if orb.fall_time_data is not None:\n",
        "    print(\"Fall Time Data (frames from peak to baseline)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.fall_time_data.head(10))\n",
        "    \n",
        "    # Note about interpretation\n",
        "    print(\"\\nğŸ’¡ To convert to seconds: divide by your frame rate\")\n",
        "    print(f\"   Example: 15 frames at 30 fps = {15/30:.2f} seconds\")\n",
        "    \n",
        "    # Compare rise vs fall times\n",
        "    if orb.rise_time_data is not None:\n",
        "        print(\"\\nğŸ“Š Rise vs Fall Time Comparison:\")\n",
        "        rise_mean = orb.rise_time_data['Rise Times'].mean()\n",
        "        fall_mean = orb.fall_time_data['Fall Times'].mean()\n",
        "        print(f\"   Mean rise time: {rise_mean:.2f} frames\")\n",
        "        print(f\"   Mean fall time: {fall_mean:.2f} frames\")\n",
        "        print(f\"   Ratio (fall/rise): {fall_mean/rise_mean:.2f}x\")\n",
        "else:\n",
        "    print(\"âŒ No fall time data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.6: Peak Amplitude Data (Transient Height)\n",
        "\n",
        "### What It Measures\n",
        "**Peak amplitude** = The height of each calcium transient, measured as Î”F/Fâ‚€ (change in fluorescence relative to baseline fluorescence).\n",
        "\n",
        "### Units: Î”F/Fâ‚€\n",
        "- Values represent fractional fluorescence change (e.g., 0.25 = 25% increase)\n",
        "- Typical range: ~0.05 to ~2.0+ depending on indicator and calcium influx\n",
        "- Standard, publishable units comparable across studies\n",
        "\n",
        "### Biological Interpretation\n",
        "- **Higher amplitude** â†’ Larger calcium influx or stronger neuronal activation\n",
        "- **Lower amplitude** â†’ Smaller calcium signals\n",
        "- Useful for detecting changes in neuronal excitability or calcium channel function\n",
        "- Can indicate the \"strength\" of neuronal responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW PEAK AMPLITUDE DATA\n",
        "# -------------------------\n",
        "# This table shows the height of each calcium transient in Î”F/Fâ‚€ units.\n",
        "\n",
        "if orb.peak_amplitude_data is not None:\n",
        "    print(\"Peak Amplitude Data (Î”F/Fâ‚€ units)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.peak_amplitude_data.head(10))\n",
        "    \n",
        "    # Quick summary statistics\n",
        "    print(f\"\\nğŸ“Š Summary Statistics (Î”F/Fâ‚€):\")\n",
        "    print(f\"   Mean amplitude: {orb.peak_amplitude_data['Peak Amplitudes'].mean():.4f}\")\n",
        "    print(f\"   Median amplitude: {orb.peak_amplitude_data['Peak Amplitudes'].median():.4f}\")\n",
        "    print(f\"   Range: {orb.peak_amplitude_data['Peak Amplitudes'].min():.4f} - {orb.peak_amplitude_data['Peak Amplitudes'].max():.4f}\")\n",
        "    \n",
        "    # Interpretation help\n",
        "    print(f\"\\nğŸ’¡ Interpretation:\")\n",
        "    print(f\"   0.10 = 10% fluorescence increase\")\n",
        "    print(f\"   0.50 = 50% fluorescence increase\")\n",
        "    print(f\"   1.00 = 100% fluorescence increase (doubling)\")\n",
        "else:\n",
        "    print(\"âŒ No peak amplitude data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.7: Inter-Spike Interval Data (Peak-to-Peak Distance)\n",
        "\n",
        "### What It Measures\n",
        "**Inter-spike interval (ISI)** = The time between consecutive calcium transient peaks (in frames).\n",
        "\n",
        "### Biological Interpretation\n",
        "- **Regular ISIs** (low variability) â†’ Rhythmic/pacemaker-like firing\n",
        "- **Irregular ISIs** (high variability) â†’ Bursty or random firing patterns\n",
        "- The coefficient of variation (CV) of ISIs indicates firing regularity:\n",
        "  - CV < 1: More regular than random\n",
        "  - CV = 1: Random (Poisson-like) firing  \n",
        "  - CV > 1: Bursty firing patterns\n",
        "- Useful for identifying oscillatory activity or changes in firing patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW INTER-SPIKE INTERVAL DATA\n",
        "# -------------------------------\n",
        "# This table shows the time between consecutive peaks for each neuron.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "if orb.peak_to_peak_data is not None:\n",
        "    print(\"Inter-Spike Interval Data (frames between consecutive peaks)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nFirst 10 rows:\")\n",
        "    display(orb.peak_to_peak_data.head(10))\n",
        "    \n",
        "    # Calculate firing regularity (coefficient of variation)\n",
        "    print(\"\\nğŸ“Š Firing Regularity Analysis:\")\n",
        "    isi_data = orb.peak_to_peak_data.dropna(subset=['Inter-Spike Intervals'])\n",
        "    \n",
        "    if len(isi_data) > 0:\n",
        "        # Calculate CV per neuron\n",
        "        isi_cv = isi_data.groupby(['Sample', 'Neuron'])['Inter-Spike Intervals'].agg(\n",
        "            lambda x: x.std() / x.mean() if len(x) > 1 and x.mean() > 0 else np.nan\n",
        "        ).dropna()\n",
        "        \n",
        "        if len(isi_cv) > 0:\n",
        "            print(f\"   Mean ISI: {isi_data['Inter-Spike Intervals'].mean():.2f} frames\")\n",
        "            print(f\"   Mean CV across neurons: {isi_cv.mean():.3f}\")\n",
        "            print(f\"\\n   Interpretation:\")\n",
        "            mean_cv = isi_cv.mean()\n",
        "            if mean_cv < 0.5:\n",
        "                print(\"   â†’ Very regular firing (rhythmic/oscillatory)\")\n",
        "            elif mean_cv < 1.0:\n",
        "                print(\"   â†’ Moderately regular firing\")\n",
        "            else:\n",
        "                print(\"   â†’ Irregular/bursty firing patterns\")\n",
        "else:\n",
        "    print(\"âŒ No inter-spike interval data available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW CLUSTERING DATA\n",
        "# --------------------\n",
        "# This table shows the quality of neuron grouping for each sample.\n",
        "\n",
        "if orb.silhouette_scores_data is not None:\n",
        "    print(\"Clustering Quality (Silhouette Scores)\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"\\nSilhouette scores by sample:\")\n",
        "    display(orb.silhouette_scores_data)\n",
        "    \n",
        "    print(\"\\nInterpretation:\")\n",
        "    print(\"   â€¢ Score > 0.5: Strong clustering (distinct neuron groups)\")\n",
        "    print(\"   â€¢ Score 0.25-0.5: Moderate clustering\")\n",
        "    print(\"   â€¢ Score < 0.25: Weak clustering (overlapping groups)\")\n",
        "else:\n",
        "    print(\"âŒ No clustering data available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 7: Correlation & Network Analysis\n",
        "\n",
        "**Learning objective**: Understand network synchrony and run dedicated correlation analysis.\n",
        "\n",
        "---\n",
        "\n",
        "Network synchrony is a key readout in calcium imaging â€” it tells you whether neurons are firing together (coordinated activity) or independently. This section covers both the correlation metrics from `run_all()` and the dedicated `run_pwc()` method for deeper network analysis.\n",
        "\n",
        "## 7.1: Pairwise Correlation Data\n",
        "\n",
        "### What It Measures\n",
        "**Pairwise correlations** = How similar the activity patterns are between pairs of neurons.\n",
        "\n",
        "### Types of Correlations\n",
        "- **Overall** (`df_mn_pwc`) â†’ Average correlation across all neuron pairs\n",
        "- **Intra-group** (`df_mn_pwc_intra`) â†’ Correlations within the same condition/well\n",
        "- **Inter-group** (`df_mn_pwc_inter`) â†’ Correlations between different conditions/wells\n",
        "\n",
        "### Biological Interpretation\n",
        "- **High correlation** â†’ Neurons fire together; may be part of the same circuit\n",
        "- **Low correlation** â†’ Neurons fire independently\n",
        "- Compare intra vs. inter correlations to assess network synchrony between conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VIEW PAIRWISE CORRELATION DATA\n",
        "# ------------------------------\n",
        "# This table shows how synchronized neurons are within and between groups.\n",
        "\n",
        "print(\"Pairwise Correlation Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "if orb.df_mn_pwc is not None:\n",
        "    print(\"\\nOverall Correlations (all neuron pairs):\")\n",
        "    display(orb.df_mn_pwc)\n",
        "else:\n",
        "    print(\"\\nâš ï¸ No overall correlation data. Did you set group_name in run_all()?\")\n",
        "\n",
        "if orb.df_mn_pwc_intra is not None:\n",
        "    print(\"\\nIntra-group Correlations (within same condition):\")\n",
        "    display(orb.df_mn_pwc_intra)\n",
        "\n",
        "if orb.df_mn_pwc_inter is not None:\n",
        "    print(\"\\nInter-group Correlations (between conditions):\")\n",
        "    display(orb.df_mn_pwc_inter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.2: Running Dedicated Correlation Analysis with `run_pwc()`\n",
        "\n",
        "If you want to analyze network correlations **separately** from other metrics (e.g., with different filtering parameters, or without recalculating firing rates), use the dedicated `run_pwc()` method:\n",
        "\n",
        "**When to use `run_pwc()` instead of relying on `run_all()`:**\n",
        "- You've already run `run_all()` but want to re-analyze correlations with different settings\n",
        "- You only care about network synchrony, not individual neuron metrics\n",
        "- You want to compare correlation patterns across different filtering thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib\n",
        "from wizards_staff import pwc\n",
        "importlib.reload(pwc)\n",
        "# RUN PAIRWISE CORRELATION ANALYSIS ONLY\n",
        "# --------------------------------------\n",
        "# This analyzes how neurons are correlated within and between groups.\n",
        "\n",
        "orb.run_pwc(\n",
        "    group_name=\"Well\",     # Which metadata column defines your groups?\n",
        "    poly=True,             # Use polynomial fitting for smoother trends\n",
        "    p_th=75,               # Brightness filter (same as run_all)\n",
        "    size_threshold=20000,  # Size filter (same as run_all)\n",
        "    show_plots=True        # Show correlation plots\n",
        ")\n",
        "\n",
        "print(\"\\nPairwise correlation analysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Ready for Statistical Testing?\n",
        "\n",
        "You've now extracted all the core metrics from your data:\n",
        "- **Firing rates** (Section 6.1) â€” how active are your neurons?\n",
        "- **Rise times & FWHM** (Section 6.2-6.3) â€” what are the kinetics of calcium events?\n",
        "- **Clustering** (Section 6.4) â€” are there functional neuron groups?\n",
        "- **Network correlations** (Section 7) â€” how synchronized is neuronal activity?\n",
        "\n",
        "The next step is to determine whether differences between your experimental groups are **statistically significant**. Section 8 covers:\n",
        "- Proper aggregation to biological replicates (avoiding pseudoreplication)\n",
        "- Assumption checking (normality, variance homogeneity)\n",
        "- Choosing the right statistical test\n",
        "- Effect size interpretation and power analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 8: Statistical Analysis of Group Differences\n",
        "\n",
        "**Learning objective**: Perform rigorous statistical comparisons between experimental groups using proper methods for calcium imaging data.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Proper Statistical Analysis Matters\n",
        "\n",
        "When analyzing calcium imaging data, it's crucial to:\n",
        "\n",
        "1. **Avoid pseudoreplication**: Individual neurons are *technical replicates* within a sample. Statistical tests should be performed on *sample-level* summaries (biological replicates).\n",
        "\n",
        "2. **Check assumptions**: Different tests have different requirements (normality, equal variance).\n",
        "\n",
        "3. **Report effect sizes**: P-values alone don't tell you if an effect is biologically meaningful.\n",
        "\n",
        "4. **Correct for multiple comparisons**: When running many tests, adjust p-values to control false discoveries.\n",
        "\n",
        "The `wizards_staff.stats` module handles all of this for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORT STATISTICAL ANALYSIS TOOLS\n",
        "# =============================================================================\n",
        "\n",
        "from wizards_staff.stats import (\n",
        "    # Core functions\n",
        "    prepare_for_stats,\n",
        "    StatsConfig,\n",
        "    \n",
        "    # Statistical tests\n",
        "    compare_two_groups,\n",
        "    compare_multiple_groups,\n",
        "    \n",
        "    # Assumption checking\n",
        "    check_all_assumptions,\n",
        "    \n",
        "    # Effect sizes\n",
        "    cohens_d,\n",
        "    \n",
        "    # Power analysis\n",
        "    calculate_required_n,\n",
        "    calculate_achieved_power,\n",
        "    calculate_detectable_effect,\n",
        "    \n",
        "    # Visualization\n",
        "    plot_group_comparison,\n",
        "    plot_power_curve,\n",
        ")\n",
        "\n",
        "print(\"âœ… Statistical analysis tools loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.1: Prepare Your Data for Statistics\n",
        "\n",
        "**The most important step!** This aggregates your neuron-level data to sample-level summaries.\n",
        "\n",
        "### Why is this critical?\n",
        "- You have ~100 neurons per sample, but maybe only 5 samples per group\n",
        "- Using neuron-level data would give you n=500 when you really have n=5\n",
        "- This \"pseudoreplication\" inflates your statistical power artificially\n",
        "- Result: False positives and unreproducible findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 1: PREPARE YOUR DATA\n",
        "# =============================================================================\n",
        "# This step aggregates neuron-level measurements to sample-level summaries.\n",
        "\n",
        "# Prepare firing rate data for statistical analysis\n",
        "frpm_stats_df = prepare_for_stats(\n",
        "    orb,\n",
        "    metric=\"frpm\",\n",
        "    aggregate=True,  # Aggregate neurons to sample-level (RECOMMENDED)\n",
        "    metadata_cols=[\"Well\"]  # Include experimental grouping columns\n",
        ")\n",
        "\n",
        "# View the prepared data\n",
        "print(\"Sample-level summary statistics:\")\n",
        "print(f\"Number of biological replicates: {len(frpm_stats_df)}\")\n",
        "print(f\"Groups: {frpm_stats_df['Well'].unique()}\")\n",
        "print()\n",
        "display(frpm_stats_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 1b: ADD TREATMENT GROUPS\n",
        "# =============================================================================\n",
        "# The statistical functions need a column with treatment groups (e.g., \"Control\" vs \"Drug\").\n",
        "# Map your Well IDs to treatment groups based on your experimental design.\n",
        "\n",
        "# EXAMPLE: Map well rows to treatment groups\n",
        "# In this demo plate layout, we split wells into two groups by row letter:\n",
        "#   - Wells in rows F, G, H = \"Control\"\n",
        "#   - Wells in rows I, J, K = \"Drug\"\n",
        "# \n",
        "# âš ï¸ MODIFY THIS MAPPING for your actual experimental design!\n",
        "\n",
        "def well_to_treatment(well):\n",
        "    \"\"\"Convert well ID to treatment group based on row letter.\"\"\"\n",
        "    row = well[0].upper()  # First character is the row (e.g., 'F' from 'F02')\n",
        "    # Split alphabet roughly in half for demo purposes\n",
        "    if row in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']:\n",
        "        return \"Control\"\n",
        "    else:  # I, J, K, L, M, N, O, P\n",
        "        return \"Drug\"\n",
        "\n",
        "frpm_stats_df[\"Treatment\"] = frpm_stats_df[\"Well\"].apply(well_to_treatment)\n",
        "\n",
        "# Verify the treatment mapping - should show exactly 2 groups\n",
        "print(\"Treatment groups created:\")\n",
        "print(frpm_stats_df.groupby(\"Treatment\").size())\n",
        "print(f\"\\nDataFrame now has columns: {list(frpm_stats_df.columns)}\")\n",
        "print(f\"\\nâœ… Ready for two-group comparison!\" if frpm_stats_df[\"Treatment\"].nunique() == 2 else \"âš ï¸ Check your mapping - need exactly 2 groups\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.2: Check Statistical Assumptions\n",
        "\n",
        "Before running statistical tests, verify your data meets the assumptions. This determines whether to use **parametric** (e.g., t-test) or **non-parametric** (e.g., Mann-Whitney) tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 2: CHECK STATISTICAL ASSUMPTIONS\n",
        "# =============================================================================\n",
        "\n",
        "assumptions = check_all_assumptions(\n",
        "    data=frpm_stats_df,\n",
        "    group_col=\"Treatment\",  # Your experimental grouping column\n",
        "    metric_col=\"mean_Firing Rate Per Min\",\n",
        "    test_type=\"two_group\"\n",
        ")\n",
        "\n",
        "# Print the assumption check report\n",
        "print(assumptions[\"report\"])\n",
        "print(f\"\\nRecommended approach: {assumptions['recommendation']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.3: Compare Two Groups\n",
        "\n",
        "Now run the statistical comparison. The `compare_two_groups()` function:\n",
        "- Chooses the appropriate test based on your assumptions\n",
        "- Calculates effect size with 95% confidence interval\n",
        "- Generates a plain-language interpretation\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "| Parameter | Your Choice | Alternatives |\n",
        "|-----------|-------------|--------------|\n",
        "| `group_col` | `\"Treatment\"` | Any column with exactly 2 groups (e.g., `\"Genotype\"`, `\"Condition\"`) |\n",
        "| `metric_col` | `\"mean_Firing Rate Per Min\"` | Any metric column from your stats dataframe |\n",
        "| `parametric` | `\"auto\"` | `True` (force t-test), `False` (force Mann-Whitney) |\n",
        "\n",
        "ğŸ’¡ **Tip**: If you have more than 2 groups, use `compare_multiple_groups()` insteadâ€”see Section 18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STEP 3: COMPARE EXPERIMENTAL GROUPS\n",
        "# =============================================================================\n",
        "\n",
        "# Configure statistical analyses (optional - uses sensible defaults)\n",
        "config = StatsConfig(\n",
        "    alpha=0.05,           # Significance level\n",
        "    correction_method=\"fdr_bh\",  # False discovery rate correction for multiple tests\n",
        "    min_samples_per_group=3      # Minimum biological replicates\n",
        ")\n",
        "\n",
        "# Compare two groups\n",
        "# NOTE: Use your experimental grouping column (e.g., \"Treatment\"), not individual well IDs\n",
        "result = compare_two_groups(\n",
        "    data=frpm_stats_df,\n",
        "    group_col=\"Treatment\",  # Changed from \"Well\" to use our 2-group column\n",
        "    metric_col=\"mean_Firing Rate Per Min\",\n",
        "    parametric=\"auto\",  # Automatically choose based on assumptions\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Print human-readable summary\n",
        "print(result.summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALIZE THE COMPARISON\n",
        "# =============================================================================\n",
        "\n",
        "# Create a publication-ready comparison plot\n",
        "fig = plot_group_comparison(\n",
        "    data=frpm_stats_df,\n",
        "    group_col=\"Treatment\",  # Changed from \"Well\" to use our 2-group column\n",
        "    metric_col=\"mean_Firing Rate Per Min\",\n",
        "    stats_result=result,\n",
        "    plot_type=\"box\",\n",
        "    show_points=True,\n",
        "    title=\"Firing Rate by Treatment Group\",\n",
        "    ylabel=\"Firing Rate (spikes/min)\",  # Clean y-axis label\n",
        "    xlabel=\"Treatment\"\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.4: Power Analysis\n",
        "\n",
        "Power analysis helps you understand:\n",
        "- **Before experiment**: How many samples do you need?\n",
        "- **After experiment**: What effects could you have detected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# POWER ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "# How many samples would I need to detect a medium effect?\n",
        "required = calculate_required_n(\n",
        "    effect_size=0.5,  # Medium effect (Cohen's d)\n",
        "    power=0.80,       # 80% power (conventional)\n",
        "    alpha=0.05,\n",
        "    test_type=\"two_sample_t\"\n",
        ")\n",
        "\n",
        "print(\"ğŸ“Š Sample Size Planning\")\n",
        "print(\"=\" * 60)\n",
        "print(required[\"interpretation\"])\n",
        "\n",
        "# What's the minimum effect I could detect with my current samples?\n",
        "n_per_group = len(frpm_stats_df) // 2  # Approximate\n",
        "\n",
        "detectable = calculate_detectable_effect(\n",
        "    n_per_group=n_per_group,\n",
        "    power=0.80\n",
        ")\n",
        "\n",
        "print(\"\\nSensitivity Analysis\")\n",
        "print(\"=\" * 60)\n",
        "print(detectable[\"interpretation\"])\n",
        "\n",
        "# Visualize power relationships\n",
        "fig = plot_power_curve(n_per_group=n_per_group)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Statistical Analysis Quick Reference\n",
        "\n",
        "### Which Test to Use?\n",
        "\n",
        "| Situation | Recommended Test |\n",
        "|-----------|-----------------|\n",
        "| 2 groups, normal data | Independent t-test |\n",
        "| 2 groups, non-normal data | Mann-Whitney U |\n",
        "| 2 paired groups | Paired t-test or Wilcoxon |\n",
        "| 3+ groups, normal data | One-way ANOVA |\n",
        "| 3+ groups, non-normal data | Kruskal-Wallis |\n",
        "| Correlation (normal) | Pearson |\n",
        "| Correlation (non-normal) | Spearman |\n",
        "\n",
        "### Effect Size Interpretation\n",
        "\n",
        "| Cohen's d | Interpretation |\n",
        "|-----------|---------------|\n",
        "| < 0.2 | Negligible |\n",
        "| 0.2 - 0.5 | Small |\n",
        "| 0.5 - 0.8 | Medium |\n",
        "| > 0.8 | Large |\n",
        "\n",
        "### Key Principles\n",
        "\n",
        "1. **Always aggregate to biological replicates** - neurons within a sample are NOT independent\n",
        "2. **Check assumptions** before choosing a test\n",
        "3. **Report effect sizes** alongside p-values\n",
        "4. **Correct for multiple comparisons** when running many tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 9: Visualizations & Publication Figures\n",
        "\n",
        "**Learning objective**: Generate and customize plots for your data.\n",
        "\n",
        "---\n",
        "\n",
        "Beyond the automatic plots from `run_all()`, you can create custom visualizations for presentations and publications.\n",
        "\n",
        "## 9.1: Compare Metrics Between Groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This plot shows average firing rates for each condition/well.\n",
        "from wizards_staff.plotting import plot_metric_by_group\n",
        "\n",
        "# Simple one-liner to plot FRPM by group\n",
        "plot_metric_by_group(orb, \n",
        "                    metric=\"frpm\", \n",
        "                    group_col=\"Well\", \n",
        "                    show_plots=True,\n",
        "                    aggregate=False,\n",
        "                    show_individual_points=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting Other Metrics\n",
        "\n",
        "The `plot_metric_by_group()` function works with all calculated metrics:\n",
        "\n",
        "| Metric | Description | Time Convertible |\n",
        "|--------|-------------|------------------|\n",
        "| `frpm` | Firing Rate Per Minute | âŒ |\n",
        "| `rise_time` | Calcium signal rise times | âœ… â†’ seconds/ms |\n",
        "| `fwhm` | Full Width at Half Maximum (event duration) | âœ… â†’ seconds/ms |\n",
        "| `spike_counts` | Number of spikes per neuron | âŒ |\n",
        "| `roundness` | Cell/organoid shape metric | âŒ |\n",
        "| `diameter` | Cell/organoid size | âŒ |\n",
        "| `area` | Cell/organoid area | âŒ |\n",
        "| `silhouette` | Clustering quality score | âŒ |\n",
        "\n",
        "**Options:**\n",
        "- **Plot types**: `\"bar\"`, `\"box\"`, `\"violin\"`\n",
        "- **Time units**: `\"ms\"` (milliseconds) or `\"s\"` (seconds) â€” auto-converts using frame rate from metadata\n",
        "- **Palettes**: `\"Set2\"`, `\"Dark2\"`, `\"tab10\"` (categorical) or custom colors list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Box plot of FWHM (event duration) in milliseconds\n",
        "# The function auto-extracts frame rate from metadata to convert frames â†’ time\n",
        "plot_metric_by_group(orb, \n",
        "                    metric=\"fwhm\",\n",
        "                    group_col=\"Well\", \n",
        "                    plot_type=\"box\", \n",
        "                    time_unit=\"ms\",\n",
        "                    aggregate=False,\n",
        "                    show_individual_points=True)\n",
        "\n",
        "# Example: Rise time in seconds with a different color palette\n",
        "# plot_metric_by_group(orb, metric=\"rise_time\", group_col=\"Well\", \n",
        "#                      plot_type=\"violin\", time_unit=\"s\", palette=\"Dark2\")\n",
        "\n",
        "# Example: Custom colors for your groups\n",
        "# plot_metric_by_group(orb, metric=\"frpm\", group_col=\"Well\",\n",
        "#                      colors=['#2ecc71', '#e74c3c', '#3498db', '#9b59b6'])\n",
        "\n",
        "# Available metrics: \"frpm\", \"fwhm\", \"rise_time\", \"spike_counts\", \"roundness\", \"diameter\", \"area\", \"silhouette\"\n",
        "# Available plot types: \"bar\", \"box\", \"violin\"\n",
        "# Recommended palettes: \"Set2\", \"Dark2\", \"tab10\", \"Paired\" (categorical), \"Blues\", \"viridis\" (sequential)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9.2: Using Built-in Plotting Functions\n",
        "\n",
        "Wizards Staff includes several specialized plotting functions for individual samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IMPORT PLOTTING FUNCTIONS\n",
        "# -------------------------\n",
        "from wizards_staff.plotting import (\n",
        "    plot_spatial_activity_map,  # Shows where neurons are located\n",
        "    plot_dff_activity,          # Shows calcium traces over time\n",
        "    plot_cluster_activity       # Shows neuron groupings\n",
        ")\n",
        "\n",
        "print(\"Plotting functions loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PLOT FOR A SPECIFIC SAMPLE\n",
        "# --------------------------\n",
        "# Get the first sample to demonstrate plotting functions.\n",
        "\n",
        "# Get one sample from the Orb\n",
        "sample_iterator = orb.shatter()  # This lets us access individual samples\n",
        "shard = next(sample_iterator)    # Get the first sample\n",
        "\n",
        "print(f\"Working with sample: {shard.sample_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPATIAL ACTIVITY MAP\n",
        "# --------------------\n",
        "# This shows where each detected neuron is located in your field of view.\n",
        "# Each colored blob is one neuron's spatial footprint.\n",
        "\n",
        "# First, apply filtering to get good neurons\n",
        "filtered_idx = shard.spatial_filtering(\n",
        "    p_th=75,               # Brightness threshold\n",
        "    size_threshold=20000,  # Size threshold\n",
        "    plot=False,            # Don't show the filtering plot\n",
        "    silence=True           # Don't print messages\n",
        ")\n",
        "\n",
        "print(f\"Found {len(filtered_idx)} neurons after filtering\")\n",
        "\n",
        "# Plot the spatial map\n",
        "plot_spatial_activity_map(\n",
        "    im_min=shard.get_input('minprojection'),  # Background image\n",
        "    cnm_A=shard.get_input('cnm_A'),           # Neuron locations\n",
        "    cnm_idx=filtered_idx,                      # Which neurons to show\n",
        "    sample_name=shard.sample_name,\n",
        "    clustering=False,      # Color randomly (set True to color by functional group)\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPATIAL ACTIVITY MAP WITH CLUSTERING\n",
        "# ------------------------------------\n",
        "# Same as the spatial map above, but colors neurons by their functional cluster.\n",
        "# Neurons with the same color fire together!\n",
        "\n",
        "plot_spatial_activity_map(\n",
        "    im_min=shard.get_input('minprojection'),\n",
        "    cnm_A=shard.get_input('cnm_A'),\n",
        "    cnm_idx=filtered_idx,\n",
        "    sample_name=shard.sample_name,\n",
        "    clustering=True,                          # Color by cluster!\n",
        "    dff_dat=shard.get_input('dff_dat'),       # Required for clustering\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CALCIUM TRACE PLOT\n",
        "# ------------------\n",
        "# This shows the activity of each neuron over time.\n",
        "# Each row is one neuron; brighter colors = higher calcium (more activity).\n",
        "\n",
        "# Get frame rate from this sample's metadata\n",
        "sample_frate = int(shard.metadata['Frate'].iloc[0])\n",
        "\n",
        "plot_dff_activity(\n",
        "    dff_dat=shard.get_input('dff_dat'),  # Calcium traces\n",
        "    cnm_idx=filtered_idx,                 # Which neurons to show\n",
        "    frate=sample_frate,                   # Frame rate from metadata\n",
        "    sample_name=shard.sample_name,\n",
        "    max_z=0.6,                            # Color scale maximum\n",
        "    begin_tp=0,                           # Start frame\n",
        "    end_tp=1000,                          # End frame (first ~33 sec at 30 fps)\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CLUSTER ACTIVITY PLOT\n",
        "# ---------------------\n",
        "# This groups neurons by their activity patterns and shows each cluster.\n",
        "# Neurons in the same cluster fire with similar patterns.\n",
        "\n",
        "plot_cluster_activity(\n",
        "    dff_dat=shard.get_input('dff_dat'),\n",
        "    filtered_idx=filtered_idx,\n",
        "    sample_name=shard.sample_name,\n",
        "    min_clusters=2,      # Minimum number of groups to try\n",
        "    max_clusters=10,     # Maximum number of groups to try\n",
        "    norm=True,           # Normalize activity for comparison\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 10: Exporting Results & Reports\n",
        "\n",
        "**Learning objective**: Save your results for further analysis and publication.\n",
        "\n",
        "---\n",
        "\n",
        "## 10.1: Automatic Export (If You Used `save_files=True`)\n",
        "\n",
        "If you ran `orb.run_all()` with `save_files=True`, your results are already saved as CSV files in the output folder.\n",
        "\n",
        "## 10.2: Manual Export\n",
        "\n",
        "You can also manually save specific results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SAVE ALL RESULTS TO CSV FILES\n",
        "# -----------------------------\n",
        "# This saves your results as spreadsheet-compatible CSV files.\n",
        "\n",
        "import os\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "export_folder = \"./exported_results/\"\n",
        "os.makedirs(export_folder, exist_ok=True)\n",
        "\n",
        "# Save all available results\n",
        "orb.save_results(\n",
        "    outdir=export_folder,\n",
        "    result_names=[\n",
        "        \"rise_time_data\",        # Rise times\n",
        "        \"fwhm_data\",             # Event durations\n",
        "        \"frpm_data\",             # Firing rates\n",
        "        \"mask_metrics_data\",     # Cell shape metrics (if available)\n",
        "        \"silhouette_scores_data\", # Clustering quality\n",
        "        \"df_mn_pwc\",             # Overall correlations\n",
        "        \"df_mn_pwc_intra\",       # Within-group correlations\n",
        "        \"df_mn_pwc_inter\"        # Between-group correlations\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(f\"\\n Results saved to: {export_folder}\")\n",
        "print(\"\\nFiles created:\")\n",
        "for f in os.listdir(export_folder):\n",
        "    if f.endswith('.csv'):\n",
        "        print(f\"   â€¢ {f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wizards_staff.stats import quick_report\n",
        "\n",
        "# Generate a complete HTML report with one line\n",
        "quick_report(orb, group_col=\"Treatment\", output_path=\"analysis_report.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## End of Part 2\n",
        "\n",
        "You've completed the **Unpaired Group Comparisons** workflow! ğŸ‰\n",
        "\n",
        "**What you accomplished:**\n",
        "- Ran the complete analysis pipeline\n",
        "- Understood firing rate, rise time, FWHM, and network correlation metrics\n",
        "- Performed rigorous statistical comparisons\n",
        "- Created publication-ready figures\n",
        "- Exported your results\n",
        "\n",
        "---\n",
        "\n",
        "## What About Paired Data?\n",
        "\n",
        "If you have **before/after** measurements on the same samples (e.g., baseline â†’ drug treatment), you may want to use **Drug Response Analysis** instead.\n",
        "\n",
        "â¡ï¸ **Continue to Part 3 (Section 11)** for paired baseline-dosing workflows.\n",
        "\n",
        "â¡ï¸ **Or skip to Part 4 (Section 17)** for advanced topics and troubleshooting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 3: Paired Drug Response Analysis\n",
        "\n",
        "*For experiments where the same samples are imaged before and after treatment.*\n",
        "\n",
        "This part covers:\n",
        "- Setting up paired data from two Orbs (baseline + dosing)\n",
        "- Computing fold changes and percent changes\n",
        "- Statistical tests for paired comparisons\n",
        "- Visualizing drug effects\n",
        "\n",
        "---\n",
        "\n",
        "# Section 11: When to Use Drug Response Analysis\n",
        "\n",
        "**Learning objective**: Understand when paired analysis is appropriate and how to organize your data.\n",
        "\n",
        "---\n",
        "\n",
        "Drug response analysis is designed for **paired experimental designs** where:\n",
        "- The **same sample** is imaged **twice** (before and after drug treatment)\n",
        "- You want to measure **fold change** or **percent change** in activity\n",
        "- You need to account for **sample-to-sample variability** by using each sample as its own control\n",
        "\n",
        "### Common Use Cases\n",
        "\n",
        "| Experimental Design | Example |\n",
        "|--------------------|---------|\n",
        "| Acute drug effects | Image organoid â†’ apply TTX â†’ image same organoid |\n",
        "| Dose-response curves | Baseline â†’ 1Î¼M â†’ 10Î¼M â†’ 100Î¼M (sequential imaging) |\n",
        "| Washout experiments | Baseline â†’ drug â†’ wash â†’ measure recovery |\n",
        "| Stimulation studies | Baseline â†’ optogenetic/electrical stim â†’ measure response |\n",
        "\n",
        "### Key Advantages of Paired Analysis\n",
        "\n",
        "1. **Increased statistical power** - Each sample serves as its own control\n",
        "2. **Accounts for baseline variability** - Normalizes away sample-to-sample differences\n",
        "3. **Biologically intuitive** - \"2x increase in firing rate\" is clearer than \"treated group has mean of 15 vs control mean of 8\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 12: Setting Up Paired Data\n",
        "\n",
        "**Learning objective**: Organize your data for paired analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## Data Organization\n",
        "\n",
        "For drug response analysis, you'll have **two separate Lizard-Wizard runs** (recommended approach):\n",
        "\n",
        "```\n",
        "/path/to/baseline_results/     â† Imaging BEFORE drug treatment\n",
        "â”œâ”€â”€ Sample_A1_pre_dff-dat.npy\n",
        "â”œâ”€â”€ Sample_A1_pre_cnm-A.npy\n",
        "â”œâ”€â”€ Sample_A2_pre_dff-dat.npy\n",
        "â”œâ”€â”€ ...\n",
        "\n",
        "/path/to/dosing_results/       â† Imaging AFTER drug treatment  \n",
        "â”œâ”€â”€ Sample_A1_post_dff-dat.npy\n",
        "â”œâ”€â”€ Sample_A1_post_cnm-A.npy\n",
        "â”œâ”€â”€ Sample_A2_post_dff-dat.npy\n",
        "â”œâ”€â”€ ...\n",
        "```\n",
        "\n",
        "### Metadata Files\n",
        "\n",
        "The metadata files for both runs should have matching `Well` values to enable pairing:\n",
        "\n",
        "**Baseline metadata:**\n",
        "```csv\n",
        "Sample,Well,Frate,Treatment\n",
        "Sample_A1_pre,A1,30,Control\n",
        "Sample_A2_pre,A2,30,Control\n",
        "Sample_B1_pre,B1,30,DrugX\n",
        "Sample_B2_pre,B2,30,DrugX\n",
        "```\n",
        "\n",
        "**Dosing metadata:**\n",
        "```csv\n",
        "Sample,Well,Frate,Treatment\n",
        "Sample_A1_post,A1,30,Control\n",
        "Sample_A2_post,A2,30,Control  \n",
        "Sample_B1_post,B1,30,DrugX\n",
        "Sample_B2_post,B2,30,DrugX\n",
        "```\n",
        "\n",
        "ğŸ’¡ **Key point**: The `Well` values must match between baseline and dosing for pairing to work!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 13: Running the Drug Response Comparison\n",
        "\n",
        "**Learning objective**: Execute the drug response analysis workflow.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# DRUG RESPONSE ANALYSIS: Complete Workflow\n",
        "# =============================================================================\n",
        "\n",
        "from wizards_staff import Orb\n",
        "from wizards_staff.drug_response import compare_baseline_dosing\n",
        "\n",
        "# Step 1: Set your paths\n",
        "# -----------------------\n",
        "# Update these paths to match your data location\n",
        "\n",
        "BASELINE_FOLDER = \"/path/to/baseline_results\"   # Pre-drug imaging\n",
        "DOSING_FOLDER = \"/path/to/dosing_results\"       # Post-drug imaging\n",
        "METADATA_BASELINE = \"/path/to/metadata_baseline.csv\"\n",
        "METADATA_DOSING = \"/path/to/metadata_dosing.csv\"  # Or same as baseline if structure matches\n",
        "\n",
        "# Step 2: Create Orbs for both timepoints\n",
        "# ----------------------------------------\n",
        "print(\"Creating Orbs for baseline and dosing data...\")\n",
        "\n",
        "orb_baseline = Orb(\n",
        "    results_folder=BASELINE_FOLDER,\n",
        "    metadata_file_path=METADATA_BASELINE\n",
        ")\n",
        "\n",
        "orb_dosing = Orb(\n",
        "    results_folder=DOSING_FOLDER, \n",
        "    metadata_file_path=METADATA_DOSING\n",
        ")\n",
        "\n",
        "print(f\"Baseline: {orb_baseline.num_shards} samples loaded\")\n",
        "print(f\"Dosing: {orb_dosing.num_shards} samples loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CREATE SYNTHETIC DOSING ORB FOR TESTING\n",
        "# =============================================================================\n",
        "import numpy as np\n",
        "\n",
        "class SyntheticOrb:\n",
        "    \"\"\"Minimal orb-like object for testing drug response analysis.\"\"\"\n",
        "    def __init__(self, real_orb, multiplier_range=(0.5, 4.0), seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.metadata = real_orb.metadata.copy()\n",
        "        \n",
        "        # Copy shards reference (needed for sample pairing)\n",
        "        self._shards = real_orb._shards\n",
        "        \n",
        "        # Copy and scale FRPM data\n",
        "        if real_orb.frpm_data is not None:\n",
        "            self._frpm_data = real_orb.frpm_data.copy()\n",
        "            multipliers = np.random.uniform(*multiplier_range, size=len(self._frpm_data))\n",
        "            self._frpm_data[\"Firing Rate Per Min\"] = self._frpm_data[\"Firing Rate Per Min\"] * multipliers\n",
        "        else:\n",
        "            self._frpm_data = None\n",
        "            \n",
        "        # Copy and scale rise time data\n",
        "        if real_orb.rise_time_data is not None:\n",
        "            self._rise_time_data = real_orb.rise_time_data.copy()\n",
        "            multipliers = np.random.uniform(*multiplier_range, size=len(self._rise_time_data))\n",
        "            self._rise_time_data[\"Rise Times\"] = self._rise_time_data[\"Rise Times\"] * multipliers\n",
        "        else:\n",
        "            self._rise_time_data = None\n",
        "            \n",
        "        # Copy and scale FWHM data  \n",
        "        if real_orb.fwhm_data is not None:\n",
        "            self._fwhm_data = real_orb.fwhm_data.copy()\n",
        "            multipliers = np.random.uniform(*multiplier_range, size=len(self._fwhm_data))\n",
        "            self._fwhm_data[\"FWHM Values\"] = self._fwhm_data[\"FWHM Values\"] * multipliers\n",
        "        else:\n",
        "            self._fwhm_data = None\n",
        "    \n",
        "    @property\n",
        "    def frpm_data(self):\n",
        "        return self._frpm_data\n",
        "    \n",
        "    @property\n",
        "    def rise_time_data(self):\n",
        "        return self._rise_time_data\n",
        "    \n",
        "    @property\n",
        "    def fwhm_data(self):\n",
        "        return self._fwhm_data\n",
        "\n",
        "# Create synthetic dosing from your existing analyzed orb\n",
        "orb_baseline = orb  # Your already-analyzed orb\n",
        "orb_dosing = SyntheticOrb(orb_baseline, multiplier_range=(0.5, 4.0))\n",
        "\n",
        "print(\"âœ… Created synthetic dosing orb!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Run standard analysis on BOTH timepoints\n",
        "# --------------------------------------------------\n",
        "# This computes firing rate, rise time, FWHM, etc. for each orb\n",
        "\n",
        "print(\"\\nAnalyzing baseline samples...\")\n",
        "orb_baseline.run_all(\n",
        "    frate=30,                # Adjust to your frame rate\n",
        "    show_plots=False,        # Suppress plots during batch processing\n",
        "    save_files=False         # Don't save individual files yet\n",
        ")\n",
        "\n",
        "print(\"\\nAnalyzing dosing samples...\")\n",
        "orb_dosing.run_all(\n",
        "    frate=30,\n",
        "    show_plots=False,\n",
        "    save_files=False\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Analysis complete for both timepoints!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Run drug response analysis\n",
        "# ------------------------------------\n",
        "# This pairs samples, computes fold changes, and creates visualizations\n",
        "from importlib import reload\n",
        "from wizards_staff import drug_response\n",
        "reload(drug_response)\n",
        "from wizards_staff.drug_response import compare_baseline_dosing\n",
        "\n",
        "results = compare_baseline_dosing(\n",
        "    baseline_orb=orb_baseline,\n",
        "    dosing_orb=orb_dosing,\n",
        "    pair_by=\"Well\",              # Column used to match baselineâ†”dosing samples\n",
        "    metrics=[\"frpm\", \"rise_time\", \"fwhm\"],  # Which metrics to analyze\n",
        "    normalization=\"fold_change\", # Options: \"fold_change\", \"percent_change\", \"delta\"\n",
        "    group_col=\"Treatment\",       # Optional: group results by this column\n",
        "    aggregate=True,              # Aggregate neuron-level data to sample means\n",
        "    agg_func=\"mean\",             # Aggregation function\n",
        "    time_unit=\"ms\",              # Use milliseconds (auto-detects frame_rate from metadata)\n",
        "    show_plots=True,             # Display visualizations\n",
        "    save_files=True,             # Save CSVs and plots\n",
        "    output_dir=\"./drug_response_outputs\"\n",
        ")\n",
        "\n",
        "# View summary of paired samples\n",
        "print(\"\\nSample Pairing Summary:\")\n",
        "display(results[\"pairs\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Explore the results\n",
        "# -----------------------------\n",
        "\n",
        "# View firing rate fold changes\n",
        "print(\"Firing Rate Drug Response:\")\n",
        "display(results[\"frpm\"].head())\n",
        "\n",
        "# View summary statistics by group\n",
        "if \"summary\" in results:\n",
        "    print(\"\\nSummary Statistics by Treatment Group:\")\n",
        "    display(results[\"summary\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 14: Understanding Normalization Methods\n",
        "\n",
        "**Learning objective**: Choose the right normalization for your analysis.\n",
        "\n",
        "---\n",
        "\n",
        "Drug response analysis offers several normalization options:\n",
        "\n",
        "| Method | Formula | \"No Change\" Value | Best For |\n",
        "|--------|---------|-------------------|----------|\n",
        "| **fold_change** | dosing / baseline | 1.0 | Multiplicative effects (2x, 3x increase) |\n",
        "| **percent_change** | ((dosing - baseline) / baseline) Ã— 100 | 0% | Percentage effects (+50%, -25%) |\n",
        "| **delta** | dosing - baseline | 0 | Absolute differences |\n",
        "| **log2_fold_change** | logâ‚‚(dosing / baseline) | 0 | Symmetric up/down visualization |\n",
        "\n",
        "### Interpreting Fold Change Values\n",
        "\n",
        "| Fold Change | Interpretation |\n",
        "|-------------|---------------|\n",
        "| 2.0 | Activity **doubled** after drug treatment |\n",
        "| 1.0 | **No change** - drug had no effect |\n",
        "| 0.5 | Activity **halved** (50% reduction) |\n",
        "| 0.0 | Complete **elimination** of activity |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative: Using percent_change normalization\n",
        "# -------------------------------------------------\n",
        "\n",
        "results_pct = compare_baseline_dosing(\n",
        "    baseline_orb=orb_baseline,\n",
        "    dosing_orb=orb_dosing,\n",
        "    pair_by=\"Well\",\n",
        "    metrics=[\"frpm\"],\n",
        "    normalization=\"percent_change\",  # Changed from fold_change\n",
        "    group_col=\"Treatment\",\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n",
        "\n",
        "# A percent_change of +100% = doubled, -50% = halved\n",
        "print(\"\\nPercent Change Results:\")\n",
        "display(results_pct[\"frpm\"][[\"pair_id\", \"baseline_Firing Rate Per Min\", \n",
        "                              \"dosing_Firing Rate Per Min\", \"percent_change\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 15: Statistical Tests for Paired Data\n",
        "\n",
        "**Learning objective**: Test whether drug effects are statistically significant.\n",
        "\n",
        "---\n",
        "\n",
        "After computing fold changes, you may want to test:\n",
        "\n",
        "1. **One-sample test**: Is the fold change different from 1.0 (no change)?\n",
        "2. **Two-sample test**: Is the fold change different between treatment groups?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical tests on drug response data\n",
        "# -----------------------------------------\n",
        "\n",
        "from scipy import stats as sp_stats\n",
        "import numpy as np\n",
        "\n",
        "# Get fold change values\n",
        "frpm_df = results[\"frpm\"]\n",
        "\n",
        "# TEST 1: One-sample t-test - Is overall fold change different from 1.0?\n",
        "# ----------------------------------------------------------------------\n",
        "fold_changes = frpm_df[\"fold_change\"].dropna()\n",
        "t_stat, p_value = sp_stats.ttest_1samp(fold_changes, popmean=1.0)\n",
        "\n",
        "print(\"One-Sample T-Test: Is drug effect different from no change (fold=1.0)?\")\n",
        "print(f\"   Mean fold change: {fold_changes.mean():.3f}\")\n",
        "print(f\"   t-statistic: {t_stat:.3f}\")\n",
        "print(f\"   p-value: {p_value:.4f}\")\n",
        "if p_value < 0.05:\n",
        "    direction = \"increased\" if fold_changes.mean() > 1 else \"decreased\"\n",
        "    print(f\"   âœ… Significant! Drug treatment {direction} activity.\")\n",
        "else:\n",
        "    print(f\"   âš ï¸ No significant drug effect detected.\")\n",
        "\n",
        "# TEST 2: Compare drug effect between treatment groups (if applicable)\n",
        "# ---------------------------------------------------------------------\n",
        "if \"Treatment\" in frpm_df.columns:\n",
        "    groups = frpm_df[\"Treatment\"].unique()\n",
        "    if len(groups) == 2:\n",
        "        group1_fc = frpm_df[frpm_df[\"Treatment\"] == groups[0]][\"fold_change\"].dropna()\n",
        "        group2_fc = frpm_df[frpm_df[\"Treatment\"] == groups[1]][\"fold_change\"].dropna()\n",
        "        \n",
        "        t_stat2, p_value2 = sp_stats.ttest_ind(group1_fc, group2_fc)\n",
        "        \n",
        "        print(f\"\\nTwo-Sample T-Test: Comparing {groups[0]} vs {groups[1]}\")\n",
        "        print(f\"   {groups[0]} mean fold change: {group1_fc.mean():.3f} (n={len(group1_fc)})\")\n",
        "        print(f\"   {groups[1]} mean fold change: {group2_fc.mean():.3f} (n={len(group2_fc)})\")\n",
        "        print(f\"   t-statistic: {t_stat2:.3f}\")\n",
        "        print(f\"   p-value: {p_value2:.4f}\")\n",
        "        if p_value2 < 0.05:\n",
        "            print(f\"   âœ… Significant difference between groups!\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸ No significant difference between groups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 16: Visualizing Drug Response\n",
        "\n",
        "**Learning objective**: Create publication-ready visualizations for paired data.\n",
        "\n",
        "---\n",
        "\n",
        "The drug response analysis automatically generates three types of plots:\n",
        "\n",
        "1. **Paired Line Plot** - Shows each sample's trajectory from baseline to dosing\n",
        "2. **Fold Change Distribution** - Violin/box plot of normalized values with reference line\n",
        "3. **Baseline vs Dosing Scatter** - X-Y plot with identity line (y=x)\n",
        "\n",
        "## Custom Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom plotting with individual functions\n",
        "# -------------------------------------------\n",
        "\n",
        "from wizards_staff.plotting import (\n",
        "    plot_paired_lines,\n",
        "    plot_fold_change_distribution,\n",
        "    plot_baseline_vs_dosing_scatter\n",
        ")\n",
        "\n",
        "# Get the FRPM results DataFrame\n",
        "frpm_df = results[\"frpm\"]\n",
        "\n",
        "# Custom paired line plot with different colors\n",
        "plot_paired_lines(\n",
        "    data=frpm_df,\n",
        "    metric=\"frpm\",\n",
        "    baseline_col=\"baseline_Firing Rate Per Min\",\n",
        "    dosing_col=\"dosing_Firing Rate Per Min\",\n",
        "    group_col=\"Treatment\",\n",
        "    title=\"Firing Rate: Before vs After Drug Treatment\",\n",
        "    palette=\"Dark2\",          # Different color palette\n",
        "    figsize=(10, 7),\n",
        "    line_alpha=0.8,\n",
        "    marker_size=100,\n",
        "    show_plots=True,\n",
        "    save_files=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drug Response Analysis Summary\n",
        "\n",
        "### Output Files Generated\n",
        "\n",
        "When `save_files=True`, the following outputs are created:\n",
        "\n",
        "| File | Description |\n",
        "|------|-------------|\n",
        "| `drug-response-frpm.csv` | Firing rate baseline, dosing, and fold changes |\n",
        "| `drug-response-rise_time.csv` | Rise time baseline, dosing, and fold changes |\n",
        "| `drug-response-fwhm.csv` | FWHM baseline, dosing, and fold changes |\n",
        "| `drug-response-summary.csv` | Summary statistics per group |\n",
        "| `drug_response_*_paired_lines.png` | Paired line plots |\n",
        "| `drug_response_*_distribution.png` | Fold change distribution plots |\n",
        "| `drug_response_*_scatter.png` | Baseline vs dosing scatter plots |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Part 4: Advanced Topics & Reference\n",
        "\n",
        "*Optional â€” use these sections if you need more control or encounter issues.*\n",
        "\n",
        "The sections below cover:\n",
        "- Processing individual samples with custom parameters\n",
        "- Additional statistical scenarios (ANOVA, correlations, outliers)\n",
        "- Troubleshooting common problems\n",
        "\n",
        "---\n",
        "\n",
        "# Section 17: Processing Samples Individually\n",
        "\n",
        "**Learning objective**: Customize analysis for specific samples using the `shatter()` method.\n",
        "\n",
        "---\n",
        "\n",
        "## When to Use Individual Processing\n",
        "\n",
        "Sometimes you need more control than `run_all()` provides:\n",
        "- Different parameters for different samples\n",
        "- Detailed inspection of specific samples\n",
        "- Custom analysis steps not included in `run_all()`\n",
        "\n",
        "## The `shatter()` Method\n",
        "\n",
        "The Orb can be \"shattered\" into individual **Shards**, where each Shard represents one sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PROCESS SAMPLES ONE AT A TIME\n",
        "# -----------------------------\n",
        "# This demonstrates how to access and analyze individual samples.\n",
        "\n",
        "from scipy.stats import zscore  # For spike detection\n",
        "import numpy as np\n",
        "\n",
        "# Loop through each sample (Shard) in the Orb\n",
        "for shard in orb.shatter():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing: {shard.sample_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Show available files for this sample\n",
        "    print(\"\\nAvailable data:\")\n",
        "    for item_name in shard.files.keys():\n",
        "        print(f\"   â€¢ {item_name}\")\n",
        "    \n",
        "    # Skip to next sample after showing info (remove 'break' to process all)\n",
        "    break\n",
        "\n",
        "print(\"\\n Remove the 'break' statement above to process all samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Custom Analysis for One Sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CUSTOM ANALYSIS EXAMPLE\n",
        "# -----------------------\n",
        "# This shows the step-by-step analysis that run_all() performs automatically.\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Get one sample\n",
        "shard = next(orb.shatter())\n",
        "print(f\"Analyzing: {shard.sample_name}\\n\")\n",
        "\n",
        "# Step 1: Filter neurons (remove noise and artifacts)\n",
        "filtered_idx = shard.spatial_filtering(\n",
        "    p_th=75,\n",
        "    size_threshold=20000,\n",
        "    plot=True,  # Show the filtering result\n",
        "    silence=False\n",
        ")\n",
        "print(f\"\\nStep 1: {len(filtered_idx)} neurons passed filtering\")\n",
        "\n",
        "# Step 2: Convert Î”F/Fâ‚€ to calcium signals and detect spikes\n",
        "calcium_signals, spike_events = shard.convert_f_to_cs(p=2)\n",
        "print(f\"\\nStep 2: Converted to calcium signals\")\n",
        "print(f\"   Shape: {calcium_signals.shape} (neurons Ã— time points)\")\n",
        "\n",
        "# Step 3: Z-score the spike events for threshold detection\n",
        "zscored_spikes = zscore(np.copy(spike_events), axis=1)\n",
        "print(f\"\\nStep 3: Z-scored spike events\")\n",
        "\n",
        "# Step 4: Calculate metrics for filtered neurons only\n",
        "rise_times, rise_positions = shard.calc_rise_tm(\n",
        "    calcium_signals[filtered_idx],\n",
        "    zscored_spikes[filtered_idx],\n",
        "    zscore_threshold=3\n",
        ")\n",
        "print(f\"\\nStep 4: Calculated rise times\")\n",
        "\n",
        "# Count how many events were detected\n",
        "total_events = sum(len(times) for times in rise_times.values())\n",
        "neurons_with_events = sum(1 for times in rise_times.values() if len(times) > 0)\n",
        "print(f\"   Found {total_events} events in {neurons_with_events} neurons\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accessing Raw Data\n",
        "\n",
        "You can access any data file for a sample using `shard.get_input()`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ACCESS RAW DATA FOR A SAMPLE\n",
        "# ----------------------------\n",
        "\n",
        "shard = next(orb.shatter())\n",
        "\n",
        "# Get the Î”F/Fâ‚€ data (calcium traces)\n",
        "dff_data = shard.get_input('dff_dat')\n",
        "print(f\" Î”F/Fâ‚€ data shape: {dff_data.shape}\")\n",
        "print(f\"   Rows = neurons, Columns = time points\")\n",
        "\n",
        "# Get the spatial footprints\n",
        "cnm_A = shard.get_input('cnm_A')\n",
        "print(f\"\\nSpatial footprints shape: {cnm_A.shape}\")\n",
        "\n",
        "# Get accepted component indices\n",
        "cnm_idx = shard.get_input('cnm_idx')\n",
        "print(f\"\\nâœ“ Accepted components: {len(cnm_idx)} neurons\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 18: Additional Statistical Scenarios\n",
        "\n",
        "**Learning objective**: Handle specialized statistical situations.\n",
        "\n",
        "---\n",
        "\n",
        "The following cells demonstrate statistical approaches for common experimental designs.\n",
        "\n",
        "## Scenario A: Comparing More Than Two Groups\n",
        "\n",
        "When you have 3 or more experimental conditions (e.g., multiple drug concentrations, genotypes, or timepoints), use `compare_multiple_groups()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SCENARIO A: COMPARING 3+ GROUPS\n",
        "# =============================================================================\n",
        "# If you have more than two experimental conditions, use ANOVA-like tests\n",
        "\n",
        "from wizards_staff.stats import compare_multiple_groups\n",
        "\n",
        "# Prepare your data (adjust column names to match your metadata)\n",
        "# Example: comparing firing rates across multiple timepoints\n",
        "if 'Well' in frpm_stats_df.columns:\n",
        "    n_groups = frpm_stats_df['Well'].nunique()\n",
        "    \n",
        "    if n_groups > 2:\n",
        "        result_multi = compare_multiple_groups(\n",
        "            data=frpm_stats_df,\n",
        "            group_col=\"Well\",  # Change to your grouping column\n",
        "            metric_col=\"mean_Firing Rate Per Min\",\n",
        "            post_hoc=True  # Perform pairwise comparisons\n",
        "        )\n",
        "        \n",
        "        print(result_multi.summary)\n",
        "        \n",
        "        # View post-hoc pairwise comparisons\n",
        "        if result_multi.post_hoc_table is not None:\n",
        "            print(\"\\nğŸ“Š Post-hoc Pairwise Comparisons:\")\n",
        "            display(result_multi.post_hoc_table)\n",
        "    else:\n",
        "        print(f\"Only {n_groups} groups found. Use compare_two_groups() for 2 groups.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario B: Correlation Between Metrics\n",
        "\n",
        "Test whether one metric is related to another (e.g., is firing rate correlated with cell size?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SCENARIO B: CORRELATION ANALYSIS\n",
        "# =============================================================================\n",
        "# Test relationships between continuous variables\n",
        "\n",
        "from wizards_staff.stats import test_correlation\n",
        "\n",
        "# Example: Test if FWHM correlates with firing rate\n",
        "# First, merge the data\n",
        "try:\n",
        "    fwhm_stats_df = prepare_for_stats(orb, metric=\"fwhm\", metadata_cols=[\"Well\"])\n",
        "    \n",
        "    # Merge FRPM and FWHM data\n",
        "    merged_df = frpm_stats_df.merge(\n",
        "        fwhm_stats_df[['Sample', 'mean_FWHM Values']], \n",
        "        on='Sample'\n",
        "    )\n",
        "    \n",
        "    corr_result = test_correlation(\n",
        "        merged_df,\n",
        "        x_col=\"mean_Firing Rate Per Min\",\n",
        "        y_col=\"mean_FWHM Values\",\n",
        "        method=\"auto\"  # Automatically chooses Pearson or Spearman\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ“Š Correlation: Firing Rate vs Event Duration (FWHM)\")\n",
        "    print(corr_result.summary)\n",
        "    \n",
        "    # Scatter plot\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    ax.scatter(merged_df[\"mean_Firing Rate Per Min\"], merged_df[\"mean_FWHM Values\"], alpha=0.7)\n",
        "    ax.set_xlabel('Mean Firing Rate (events/min)')\n",
        "    ax.set_ylabel('Mean FWHM (frames)')\n",
        "    ax.set_title(f'r = {corr_result.statistic:.3f}, p = {corr_result.p_value:.3f}')\n",
        "    plt.show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Could not perform correlation analysis: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scenario C: Outlier Detection\n",
        "\n",
        "Identify potential outliers that might be affecting your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SCENARIO C: OUTLIER DETECTION\n",
        "# =============================================================================\n",
        "# Identify samples with unusual values\n",
        "\n",
        "from wizards_staff.stats import detect_outliers, visualize_outliers\n",
        "\n",
        "# Detect outliers in firing rate\n",
        "outlier_result = detect_outliers(\n",
        "    data=frpm_stats_df,\n",
        "    metric_col=\"mean_Firing Rate Per Min\",\n",
        "    method=\"iqr\",  # Interquartile range method (robust)\n",
        "    group_col=\"Well\"  # Check within each group\n",
        ")\n",
        "\n",
        "print(\"ğŸ“Š Outlier Detection Results\")\n",
        "print(\"=\" * 60)\n",
        "print(outlier_result['summary'])\n",
        "print()\n",
        "print(f\"Recommendation: {outlier_result['recommendation']}\")\n",
        "\n",
        "# If outliers found, show them\n",
        "if outlier_result['n_outliers'] > 0:\n",
        "    print(\"\\nâš ï¸ Outlier samples:\")\n",
        "    outlier_samples = frpm_stats_df.loc[outlier_result['outlier_indices']]\n",
        "    display(outlier_samples[['Sample', 'Well', 'mean_Firing Rate Per Min']])\n",
        "    \n",
        "    # Visualize\n",
        "    fig = visualize_outliers(frpm_stats_df, \"mean_Firing Rate Per Min\", outlier_result, \"Well\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 19: Troubleshooting\n",
        "\n",
        "**Learning objective**: Diagnose and fix common problems.\n",
        "\n",
        "---\n",
        "\n",
        "## Common Issues and Solutions\n",
        "\n",
        "### âŒ \"Missing columns in metadata\"\n",
        "\n",
        "**Cause**: Your metadata CSV doesn't have the required columns.\n",
        "\n",
        "**Solution**:\n",
        "1. Open your metadata file\n",
        "2. Check that it has columns named exactly: `Sample`, `Well`, `Frate`\n",
        "3. Column names are case-sensitive!\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ \"No files found\" or warnings about missing files\n",
        "\n",
        "**Cause**: The `Sample` names in your metadata don't match your file names.\n",
        "\n",
        "**Solution**:\n",
        "1. Look at your actual file names (e.g., `MyExperiment_A01_dff-dat.npy`)\n",
        "2. The `Sample` column should contain: `MyExperiment_A01` (everything before `_dff-dat.npy`)\n",
        "3. Check for typos, extra spaces, or different capitalization\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ Empty plots or \"No neurons found\"\n",
        "\n",
        "**Cause**: Filtering is too strict for your data.\n",
        "\n",
        "**Solution**: Try adjusting the filtering parameters:\n",
        "```python\n",
        "orb.run_all(\n",
        "    p_th=50,              # Lower brightness threshold (was 75)\n",
        "    size_threshold=50000,  # Higher size limit (was 20000)\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ Very few spikes detected\n",
        "\n",
        "**Cause**: Z-score threshold is too high for your signal.\n",
        "\n",
        "**Solution**: Lower the threshold:\n",
        "```python\n",
        "orb.run_all(\n",
        "    zscore_threshold=2,   # More sensitive (was 3)\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ Too many spikes (noise being detected)\n",
        "\n",
        "**Cause**: Z-score threshold is too low.\n",
        "\n",
        "**Solution**: Increase the threshold:\n",
        "```python\n",
        "orb.run_all(\n",
        "    zscore_threshold=4,   # Less sensitive (was 3)\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ Wrong time scale in results\n",
        "\n",
        "**Cause**: The `Frate` value in your metadata doesn't match your actual recording frame rate.\n",
        "\n",
        "**Solution**: Check your microscope settings and update the `Frate` column in your metadata CSV.\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ Correlation analysis not running\n",
        "\n",
        "**Cause**: `group_name` not specified or doesn't match a column.\n",
        "\n",
        "**Solution**: Make sure `group_name` matches a column in your metadata:\n",
        "```python\n",
        "orb.run_all(\n",
        "    group_name=\"Well\",   # Must match a column name exactly\n",
        "    ...\n",
        ")\n",
        "```\n",
        "\n",
        "## Diagnostic Code\n",
        "\n",
        "Use these cells to debug issues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHECK YOUR METADATA\n",
        "# -------------------\n",
        "print(\"Your metadata columns:\")\n",
        "print(f\"   {list(orb.metadata.columns)}\")\n",
        "\n",
        "print(\"\\nRequired columns:\")\n",
        "print(\"   ['Sample', 'Well', 'Frate']\")\n",
        "\n",
        "# Check for required columns\n",
        "required = ['Sample', 'Well', 'Frate']\n",
        "missing = [col for col in required if col not in orb.metadata.columns]\n",
        "if missing:\n",
        "    print(f\"\\nâŒ Missing columns: {missing}\")\n",
        "else:\n",
        "    print(\"\\nâœ… All required columns present!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHECK SAMPLE NAME MATCHING\n",
        "# --------------------------\n",
        "import os\n",
        "\n",
        "print(\"Checking if sample names match files...\\n\")\n",
        "\n",
        "# Get sample names from metadata\n",
        "metadata_samples = set(orb.metadata['Sample'])\n",
        "\n",
        "# Get sample names from files\n",
        "files_in_folder = os.listdir(RESULTS_FOLDER) if os.path.exists(RESULTS_FOLDER) else []\n",
        "file_samples = set()\n",
        "for f in files_in_folder:\n",
        "    if '_dff-dat.npy' in f:\n",
        "        sample_name = f.replace('_dff-dat.npy', '')\n",
        "        file_samples.add(sample_name)\n",
        "\n",
        "# Compare\n",
        "in_both = metadata_samples & file_samples\n",
        "only_in_metadata = metadata_samples - file_samples\n",
        "only_in_files = file_samples - metadata_samples\n",
        "\n",
        "print(f\"âœ… Matched samples: {len(in_both)}\")\n",
        "if only_in_metadata:\n",
        "    print(f\"\\nâš ï¸ In metadata but no files found: {len(only_in_metadata)}\")\n",
        "    for s in list(only_in_metadata)[:5]:\n",
        "        print(f\"   â€¢ {s}\")\n",
        "if only_in_files:\n",
        "    print(f\"\\nâš ï¸ Files exist but not in metadata: {len(only_in_files)}\")\n",
        "    for s in list(only_in_files)[:5]:\n",
        "        print(f\"   â€¢ {s}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Congratulations thats the tutorial\n",
        "\n",
        "**Youre a wizard Harry ğŸ§™â€â™‚ï¸âœ¨**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# NOTEBOOK VALIDATION\n",
        "# =============================================================================\n",
        "# Run this cell as a final check that everything worked correctly.\n",
        "\n",
        "validation_results = []\n",
        "\n",
        "# Check that orb was created and analyzed\n",
        "try:\n",
        "    assert orb is not None\n",
        "    assert hasattr(orb, 'frpm_data')\n",
        "    validation_results.append(\"âœ“ Orb analysis completed\")\n",
        "except:\n",
        "    validation_results.append(\"âš  Orb analysis not run (expected if using demo)\")\n",
        "\n",
        "# Check that statistical results exist\n",
        "try:\n",
        "    assert 'result' in dir() and result is not None\n",
        "    validation_results.append(\"âœ“ Statistical analysis completed\")\n",
        "except:\n",
        "    validation_results.append(\"âš  Statistical analysis not run\")\n",
        "\n",
        "# Check that figures were created\n",
        "import os\n",
        "if os.path.exists(\"figure_firing_rate.png\"):\n",
        "    validation_results.append(\"âœ“ Publication figures exported\")\n",
        "else:\n",
        "    validation_results.append(\"âš  Figures not saved (run Scenario F cell)\")\n",
        "\n",
        "# Print validation summary\n",
        "print(\"=\" * 50)\n",
        "print(\"NOTEBOOK VALIDATION SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "for r in validation_results:\n",
        "    print(r)\n",
        "print(\"=\" * 50)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "wizards_staff",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
