{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1a: Running the Full Analysis Pipeline without PWC\n",
    "You can run the entire analysis pipeline on a results folder by calling the `run_all` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 13:51:08.198568: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 13:51:08.212485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733953868.227929   87627 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733953868.232449   87627 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 13:51:08.249319: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7de3e06e604ab7a003e5082638403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading files for CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full: Failed to interpret file '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_histogram-pnr-cn-filter.png' as a pickle\n",
      "Error processing file CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full: 'NoneType' object is not subscriptable\n",
      "Error loading files for CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full: Could not find a backend to open `/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cnm-C.npy`` with iomode `r`.\n",
      "Error processing file CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full: 'NoneType' object is not subscriptable\n",
      "Error loading files for CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full: Failed to interpret file '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_histogram-pnr-cn-filter.png' as a pickle\n",
      "Error processing file CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full: 'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Rise Times'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m frate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Written in Frames Per Second\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the full analysis pipeline:\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m rise_time_df, fwhm_df, frpm_df, mask_metrics_df, silhouette_scores_df \u001b[38;5;241m=\u001b[39m \u001b[43mwizards_staff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Folder containing the results of the Lizard_Wizard pipeline\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43mmetadata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Path to the metadata file\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43mfrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Frame rate of the video\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43msize_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Parameter to filter out large noise \u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43mshow_plots\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Set to True to show the plots inline\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43msave_files\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Set to True to save the output files\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./lizard_wizard_outputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Directory to save the output files\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wizards-Staff/wizards_staff/wizards_cauldron.py:192\u001b[0m, in \u001b[0;36mrun_all\u001b[0;34m(results_folder, metadata_path, frate, zscore_threshold, percentage_threshold, p_th, min_clusters, max_clusters, random_seed, group_name, poly, size_threshold, show_plots, save_files, output_dir)\u001b[0m\n\u001b[1;32m    189\u001b[0m silhouette_scores_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(silhouette_scores_data)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Use explode to handle lists in DataFrames\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m rise_time_df \u001b[38;5;241m=\u001b[39m \u001b[43mrise_time_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRise Times\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRise Positions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m fwhm_df \u001b[38;5;241m=\u001b[39m fwhm_df\u001b[38;5;241m.\u001b[39mexplode([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFWHM Backward Positions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFWHM Forward Positions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFWHM Values\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpike Counts\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Append metadata to dataframes\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/wizards_staff/lib/python3.11/site-packages/pandas/core/frame.py:9849\u001b[0m, in \u001b[0;36mDataFrame.explode\u001b[0;34m(self, column, ignore_index)\u001b[0m\n\u001b[1;32m   9847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   9848\u001b[0m     mylen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m (is_list_like(x) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 9849\u001b[0m     counts0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(mylen)\n\u001b[1;32m   9850\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m   9851\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(counts0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m[c]\u001b[38;5;241m.\u001b[39mapply(mylen)):\n",
      "File \u001b[0;32m~/miniforge3/envs/wizards_staff/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/wizards_staff/lib/python3.11/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Rise Times'"
     ]
    }
   ],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "# Path to the example data folder (update this path to your own data directory)\n",
    "results_folder = '/large_storage/cmtc/public/' # Folder containing the results of the Lizard_Wizard pipeline  \n",
    "metadata_path = '/home/jesseh/metadata.csv' # Path to the metadata file\n",
    "frate = 100  # Written in Frames Per Second\n",
    "\n",
    "# Run the full analysis pipeline:\n",
    "rise_time_df, fwhm_df, frpm_df, mask_metrics_df, silhouette_scores_df = wizards_staff.run_all(results_folder,  # Folder containing the results of the Lizard_Wizard pipeline\n",
    "                                                                                            metadata_path, # Path to the metadata file\n",
    "                                                                                            frate=frate, # Frame rate of the video\n",
    "                                                                                            size_threshold=20000, # Parameter to filter out large noise \n",
    "                                                                                            show_plots = True, # Set to True to show the plots inline\n",
    "                                                                                            save_files = False, # Set to True to save the output files\n",
    "                                                                                            output_dir='./lizard_wizard_outputs' # Directory to save the output files\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1b: Running the Full Analysis Pipeline with PWC\n",
    "You can run the entire analysis pipeline including pairwise correlation calculations on a results folder by calling the `run_all` function and specifying a group name which is specified by a column name in your 'metadata_path' CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "results_folder = './path/to/results' # Folder containing the results of the Lizard_Wizard pipeline, update this path to your own data directory\n",
    "metadata_path = './path/to/metadata.csv' # Path to the metadata file, update this path to your own metadata directory\n",
    "frate = 30  # Written in Frames Per Second\n",
    "\n",
    "# Run the full analysis pipeline:\n",
    "rise_time_df, fwhm_df, frpm_df, mask_metrics_df, silhouette_scores_df = wizards_staff.run_all(results_folder,  # Folder containing the results of the Lizard_Wizard pipeline\n",
    "                                                                                            metadata_path, # Path to the metadata file\n",
    "                                                                                            frate=frate, # Frame rate of the video\n",
    "                                                                                            group_name = 'group', # Column name in the metadata file containing the group information\n",
    "                                                                                            size_threshold=20000, # Parameter to filter out large noise \n",
    "                                                                                            show_plots = True, # Set to True to show the plots inline\n",
    "                                                                                            save_files = False, # Set to True to save the output files\n",
    "                                                                                            output_dir='./lizard_wizard_outputs' # Directory to save the output files\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Running just the PWC Function\n",
    "You can run just the PWC pipeline on a results folder by calling the `run_pwc` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "group_name = 'Compound' # Column name in the metadata file containing the group information\n",
    "results_folder = './path/to/results' # Folder containing the results of the Lizard_Wizard pipeline, update this path to your own data directory\n",
    "metadata_path = './path/to/metadata.csv' # Path to the metadata file, update this path to your own metadata directory\n",
    "poly = False # Set to True to fit a polynomial to the data\n",
    "\n",
    "# Parameters for the function\n",
    "df_mn_pwc, df_mn_pwc_inter, df_mn_pwc_intra = wizards_staff.run_pwc(group_name, # Column name in the metadata file containing the group information\n",
    "                                                    metadata_path, \n",
    "                                                    results_folder, \n",
    "                                                    poly = poly, \n",
    "                                                    show_plots = False, # Set to True to show the plots inline\n",
    "                                                    save_files = False, # Set to True to save the output files\n",
    "                                                    output_dir = './lizard_wizard_outputs' # Default directory to save the output files\n",
    "                                                    )\n",
    "\n",
    "# df_mn_pwc\n",
    "df_mn_pwc_inter\n",
    "# df_mn_pwc_intra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Calculate just Firing Rate Per Minute\n",
    "\n",
    "Below is a basic framework for how one would, instead of running through and calculating all metrics/plotting functions, just one module by:\n",
    "- Gathering the necessary files for the analysis via `categorize_files`, which organizes the results from the Lizard-Wizard pipeline into a structured format for analysis.\n",
    "- Looping through each file in the categorized results and loading the required data using `load_required_files`.\n",
    "- Applying spatial filtering to remove noise in the calcium imaging data using `spatial_filtering`. This step filters the regions of interest (ROIs) based on the image data and thresholds defined, ensuring that only relevant signal areas are processed.\n",
    "- Loading the ΔF/F₀ data, which represents fluorescence changes relative to baseline levels, and converting it to calcium signals and spike events using the `convert_f_to_cs` function.\n",
    "- Z-scoring the spike events with `zscore` to normalize them, making the data easier to compare and threshold for event detection.\n",
    "- Filtering the calcium signals and spike events based on the indexing results of `spatial_filtering`.\n",
    "- Calculating the intended metric which in this case is Firing Rate Per Minute (FRPM) for each neuron using the `calc_frpm` function, which analyzes the z-scored spike events to compute firing rates based on the specified z-score threshold.\n",
    "- Storing the FRPM data in a list, which is later converted to a pandas DataFrame for further analysis or visualization.\n",
    "\n",
    "Finally, the metadata is appended to the resulting DataFrame using `append_metadata_to_dfs`, ensuring that each result is annotated with its corresponding metadata, such as image acquisition details and well positions from the plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "def categorize_files(results_folder, metadata_csv):\n",
    "    \"\"\"\n",
    "    Categorizes files in the results folder and its subfolders based on specified suffix patterns\n",
    "    and uses a metadata CSV file to create dictionary keys.\n",
    "\n",
    "    Args:\n",
    "        results_folder (str or Path): Path to the folder containing result files.\n",
    "        metadata_csv (str or Path): Path to the CSV file containing a `filename` column.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary where keys are from the `filename` column and values are lists of file paths.\n",
    "    \"\"\"\n",
    "    results_folder = Path(results_folder)  # Ensure it's a Path object\n",
    "\n",
    "    filters = [\n",
    "        'cn-filter.npy',\n",
    "        'cnm-A.npy',\n",
    "        'cnm-C.npy',\n",
    "        'cnm-S.npy',\n",
    "        'cnm-idx.npy',\n",
    "        'dff-dat.npy',\n",
    "        'f-dat.npy',\n",
    "        'pnr-filter.npy',\n",
    "        'pnr-cn-filter.png',\n",
    "        'minprojection.tif',\n",
    "        'mask.tif',\n",
    "    ]\n",
    "    \n",
    "    # Load metadata CSV\n",
    "    metadata = pd.read_csv(metadata_csv)\n",
    "    \n",
    "    # Extract filenames from the metadata\n",
    "    filenames = metadata['Sample'].tolist()\n",
    "    \n",
    "    # Dictionary to hold categorized files\n",
    "    categorized_files = defaultdict(list)\n",
    "\n",
    "    # Recursively find and filter files\n",
    "    for path in results_folder.rglob(\"*\"):\n",
    "        if path.is_file():\n",
    "            # Check if the file matches any of the filters and metadata filenames\n",
    "            for suffix in filters:\n",
    "                if path.name.endswith(suffix):\n",
    "                    # Match to a key from the metadata\n",
    "                    for key in filenames:\n",
    "                        if path.name.startswith(key):\n",
    "                            categorized_files[key].append(str(path))\n",
    "                            break\n",
    "\n",
    "    # Ensure that each entry has a mask, set to None if not present\n",
    "    for key in filenames:\n",
    "        if not any('mask' in file for file in categorized_files[key]):\n",
    "            categorized_files[key].append(None)\n",
    "\n",
    "    return categorized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = '/large_storage/cmtc/public/' # Folder containing the results of the Lizard_Wizard pipeline  \n",
    "metadata_path = '/home/jesseh/metadata.csv' # Path to the metadata file\n",
    "categorized_files = categorize_files_with_metadata(results_folder, metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full': ['/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_cn-filter.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_cnm-idx.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_histogram-pnr-cn-filter.png',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_cnm-A.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_cnm-C.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_pnr-filter.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_masked_cnm-S.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_f-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_dff-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C03_s1_FITC_full_dff-dat.npy'],\n",
       "             'CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full': ['/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_pnr-filter.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_histogram-pnr-cn-filter.png',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cnm-S.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cnm-idx.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cnm-A.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cn-filter.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_masked_cnm-C.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_dff-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_dff-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_B03_s1_FITC_full_f-dat.npy'],\n",
       "             'CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full': ['/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_cnm-C.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_cnm-S.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_pnr-filter.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_cnm-A.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_histogram-pnr-cn-filter.png',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_cnm-idx.npy',\n",
       "              '/large_storage/cmtc/public/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_masked_cn-filter.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_dff-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_dff-dat.npy',\n",
       "              '/large_storage/cmtc/public/caiman_calc-dff-f0/CMTC-Sph10142024-PLate1_Stream_C02_s1_FITC_full_f-dat.npy']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 13:50:00.384842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 13:50:00.398800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733953800.414030   84606 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733953800.418556   84606 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 13:50:00.435473: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "# Path to the example data folder (update this path to your own data directory)\n",
    "results_folder = '/large_storage/cmtc/public/' # Folder containing the results of the Lizard_Wizard pipeline  \n",
    "metadata_path = '/home/jesseh/metadata.csv' # Path to the metadata file\n",
    "# frate = 30  # Written in Frames Per Second\n",
    "p_th = 0.5  # Threshold for spatial filtering\n",
    "size_threshold = 20000  # Parameter to filter out large noise\n",
    "zscore_threshold = 2  # Threshold for z-scoring the spike events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the necessary files for the analysis\n",
    "categorized_files = categorize_files(results_folder)\n",
    "\n",
    "# Initialize lists to store data for given metric type\n",
    "frpm_data = []\n",
    "\n",
    "# Loop through file list and run analysis on each file\n",
    "for raw_filename, _ in tqdm(categorized_files.items(), desc=\"Processing files\"):\n",
    "    # Load the necessary Lizard_Wizard Output files for the current image file\n",
    "    file_data = load_required_files(categorized_files, raw_filename)\n",
    "    \n",
    "    # Apply spatial filtering to the data to remove noise\n",
    "    filtered_idx = spatial_filtering(cn_filter= file_data['cn_filter_img'], p_th = p_th, size_threshold = size_threshold, \n",
    "    cnm_A=file_data['cnm_A'], cnm_idx=file_data['cnm_idx'], im_min = file_data['im_min'], plot=False, silence=True)\n",
    "    \n",
    "    # Load the ΔF/F₀ data for the given image file and add a small constant to avoid division by zero``\n",
    "    dff = file_data['dff_dat']\n",
    "    dff += 0.0001  # Small constant added to avoid division by zero\n",
    "\n",
    "    # Convert ΔF/F₀ to calcium signals and spike events\n",
    "    calcium_signals, spike_events = convert_f_to_cs(dff, p = 2)\n",
    "\n",
    "    # Z-score the spike events\n",
    "    zscored_spike_events = zscore(np.copy(spike_events), axis = 1)\n",
    "\n",
    "    # Filter the calcium signals and z-scored spike events based on the spatial filtering\n",
    "    zscored_spike_events_filtered = zscored_spike_events[filtered_idx, :]\n",
    "    calcium_signals_filtered = calcium_signals[filtered_idx, :]\n",
    "\n",
    "    # Calculate FRPM:\n",
    "    _, frpm  = calc_frpm(zscored_spike_events, filtered_idx, frate, zscore_threshold = zscore_threshold)\n",
    "\n",
    "    # Append the FRPM data to the list\n",
    "    for neuron_idx, frpm_value in frpm.items():\n",
    "        frpm_data.append({'Filename': raw_filename,'Neuron Index': neuron_idx,'Firing Rate Per Min.': frpm_value})\n",
    "\n",
    "# Convert the frpm list to DataFrames\n",
    "frpm_df = pd.DataFrame(frpm_data)\n",
    "\n",
    "# Append metadata to dataframes\n",
    "updated_frpm_df = append_metadata_to_dfs(metadata_path, frpm = frpm_df)\n",
    "\n",
    "# Show the first few rows of the updated DataFrame\n",
    "updated_frpm_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizards_staff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
