{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1a: Running the Full Analysis Pipeline without PWC\n",
    "You can run the entire analysis pipeline on a results folder by calling the `run_all` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "# Path to the example data folder (update this path to your own data directory)\n",
    "results_folder = '/large_storage/cmtc/public/CMTC_Sph06172024/' # Folder containing the results of the Lizard_Wizard pipeline  \n",
    "metadata_path = '/large_storage/cmtc/public/CMTC_Sph06172024/metadata.csv' # Path to the metadata file\n",
    "frate = 66  # Written in Frames Per Second\n",
    "\n",
    "# Run the full analysis pipeline:\n",
    "rise_time_df, fwhm_df, frpm_df, mask_metrics_df, silhouette_scores_df = wizards_staff.run_all(results_folder,  # Folder containing the results of the Lizard_Wizard pipeline\n",
    "                                                                                            metadata_path, # Path to the metadata file\n",
    "                                                                                            frate=frate, # Frame rate of the video\n",
    "                                                                                            size_threshold=20000, # Parameter to filter out large noise \n",
    "                                                                                            show_plots = True, # Set to True to show the plots inline\n",
    "                                                                                            save_files = True, # Set to True to save the output files\n",
    "                                                                                            output_dir='/large_storage/multiomics/public/CMTC_Sph06172024_outputs/' # Directory to save the output files\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1b: Running the Full Analysis Pipeline with PWC\n",
    "You can run the entire analysis pipeline including pairwise correlation calculations on a results folder by calling the `run_all` function and specifying a group name which is specified by a column name in your 'metadata_path' CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "results_folder = './path/to/results' # Folder containing the results of the Lizard_Wizard pipeline, update this path to your own data directory\n",
    "metadata_path = './path/to/metadata.csv' # Path to the metadata file, update this path to your own metadata directory\n",
    "frate = 30  # Written in Frames Per Second\n",
    "\n",
    "# Run the full analysis pipeline:\n",
    "rise_time_df, fwhm_df, frpm_df, mask_metrics_df, silhouette_scores_df = wizards_staff.run_all(results_folder,  # Folder containing the results of the Lizard_Wizard pipeline\n",
    "                                                                                            metadata_path, # Path to the metadata file\n",
    "                                                                                            frate=frate, # Frame rate of the video\n",
    "                                                                                            group_name = 'group', # Column name in the metadata file containing the group information\n",
    "                                                                                            size_threshold=20000, # Parameter to filter out large noise \n",
    "                                                                                            show_plots = True, # Set to True to show the plots inline\n",
    "                                                                                            save_files = False, # Set to True to save the output files\n",
    "                                                                                            output_dir='./lizard_wizard_outputs' # Directory to save the output files\n",
    "                                                                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Running just the PWC Function\n",
    "You can run just the PWC pipeline on a results folder by calling the `run_pwc` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wizards_staff # import the module\n",
    "\n",
    "group_name = 'Compound' # Column name in the metadata file containing the group information\n",
    "results_folder = './path/to/results' # Folder containing the results of the Lizard_Wizard pipeline, update this path to your own data directory\n",
    "metadata_path = './path/to/metadata.csv' # Path to the metadata file, update this path to your own metadata directory\n",
    "poly = False # Set to True to fit a polynomial to the data\n",
    "\n",
    "# Parameters for the function\n",
    "df_mn_pwc, df_mn_pwc_inter, df_mn_pwc_intra = wizards_staff.run_pwc(group_name, # Column name in the metadata file containing the group information\n",
    "                                                    metadata_path, \n",
    "                                                    results_folder, \n",
    "                                                    poly = poly, \n",
    "                                                    show_plots = False, # Set to True to show the plots inline\n",
    "                                                    save_files = False, # Set to True to save the output files\n",
    "                                                    output_dir = './lizard_wizard_outputs' # Default directory to save the output files\n",
    "                                                    )\n",
    "\n",
    "# df_mn_pwc\n",
    "df_mn_pwc_inter\n",
    "# df_mn_pwc_intra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Calculate just Firing Rate Per Minute\n",
    "\n",
    "Below is a basic framework for how one would, instead of running through and calculating all metrics/plotting functions, just one module by:\n",
    "- Gathering the necessary files for the analysis via `categorize_files`, which organizes the results from the Lizard-Wizard pipeline into a structured format for analysis.\n",
    "- Looping through each file in the categorized results and loading the required data using `load_required_files`.\n",
    "- Applying spatial filtering to remove noise in the calcium imaging data using `spatial_filtering`. This step filters the regions of interest (ROIs) based on the image data and thresholds defined, ensuring that only relevant signal areas are processed.\n",
    "- Loading the ΔF/F₀ data, which represents fluorescence changes relative to baseline levels, and converting it to calcium signals and spike events using the `convert_f_to_cs` function.\n",
    "- Z-scoring the spike events with `zscore` to normalize them, making the data easier to compare and threshold for event detection.\n",
    "- Filtering the calcium signals and spike events based on the indexing results of `spatial_filtering`.\n",
    "- Calculating the intended metric which in this case is Firing Rate Per Minute (FRPM) for each neuron using the `calc_frpm` function, which analyzes the z-scored spike events to compute firing rates based on the specified z-score threshold.\n",
    "- Storing the FRPM data in a list, which is later converted to a pandas DataFrame for further analysis or visualization.\n",
    "\n",
    "Finally, the metadata is appended to the resulting DataFrame using `append_metadata_to_dfs`, ensuring that each result is annotated with its corresponding metadata, such as image acquisition details and well positions from the plate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-23 07:35:58.502036: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-23 07:35:58.624978: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734968158.671616 2975351 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734968158.685199 2975351 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-23 07:35:58.747437: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'categorize_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Gather the necessary files for the analysis\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m categorized_files \u001b[38;5;241m=\u001b[39m \u001b[43mcategorize_files\u001b[49m(results_folder)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Initialize lists to store data for given metric type\u001b[39;00m\n\u001b[1;32m     10\u001b[0m frpm_data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'categorize_files' is not defined"
     ]
    }
   ],
   "source": [
    "from wizards_staff.wizards_familiars import * # import the module\n",
    "from wizards_staff.wizards_spellbook import * # import the module\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Gather the necessary files for the analysis\n",
    "categorized_files = categorize_files(results_folder)\n",
    "\n",
    "# Initialize lists to store data for given metric type\n",
    "frpm_data = []\n",
    "\n",
    "# Loop through file list and run analysis on each file\n",
    "for raw_filename, _ in tqdm(categorized_files.items(), desc=\"Processing files\"):\n",
    "    # Load the necessary Lizard_Wizard Output files for the current image file\n",
    "    file_data = load_required_files(categorized_files, raw_filename)\n",
    "    \n",
    "    # Apply spatial filtering to the data to remove noise\n",
    "    filtered_idx = spatial_filtering(cn_filter= file_data['cn_filter_img'], p_th = p_th, size_threshold = size_threshold, \n",
    "    cnm_A=file_data['cnm_A'], cnm_idx=file_data['cnm_idx'], im_min = file_data['im_min'], plot=False, silence=True)\n",
    "    \n",
    "    # Load the ΔF/F₀ data for the given image file and add a small constant to avoid division by zero``\n",
    "    dff = file_data['dff_dat']\n",
    "    dff += 0.0001  # Small constant added to avoid division by zero\n",
    "\n",
    "    # Convert ΔF/F₀ to calcium signals and spike events\n",
    "    calcium_signals, spike_events = convert_f_to_cs(dff, p = 2)\n",
    "\n",
    "    # Z-score the spike events\n",
    "    zscored_spike_events = zscore(np.copy(spike_events), axis = 1)\n",
    "\n",
    "    # Filter the calcium signals and z-scored spike events based on the spatial filtering\n",
    "    zscored_spike_events_filtered = zscored_spike_events[filtered_idx, :]\n",
    "    calcium_signals_filtered = calcium_signals[filtered_idx, :]\n",
    "\n",
    "    # Calculate FRPM:\n",
    "    _, frpm  = calc_frpm(zscored_spike_events, filtered_idx, frate, zscore_threshold = zscore_threshold)\n",
    "\n",
    "    # Append the FRPM data to the list\n",
    "    for neuron_idx, frpm_value in frpm.items():\n",
    "        frpm_data.append({'Filename': raw_filename,'Neuron Index': neuron_idx,'Firing Rate Per Min.': frpm_value})\n",
    "\n",
    "# Convert the frpm list to DataFrames\n",
    "frpm_df = pd.DataFrame(frpm_data)\n",
    "\n",
    "# Append metadata to dataframes\n",
    "updated_frpm_df = append_metadata_to_dfs(metadata_path, frpm = frpm_df)\n",
    "\n",
    "# Show the first few rows of the updated DataFrame\n",
    "updated_frpm_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wizards_staff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
